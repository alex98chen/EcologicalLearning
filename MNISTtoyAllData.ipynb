{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "MNISTtoy.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "Q_d-CIz_uoKk",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import torch\n",
        "import torchvision as tv\n",
        "import torchvision.transforms as transforms\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "from torch import optim\n",
        "from torch.autograd import Variable\n",
        "from torch.utils.data import DataLoader\n",
        "from torchvision.utils import save_image\n",
        "from torchvision.datasets import MNIST\n",
        "import os"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-ZmEczR4uzYl",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "if not os.path.exists('./vae_img'):\n",
        "    os.mkdir('./vae_img')\n",
        "\n",
        "if not os.path.exists('./vae_img_pred'):\n",
        "    os.mkdir('./vae_img_pred')\n",
        "\n",
        "\n",
        "def to_img(x):\n",
        "    x = x.clamp(0, 1)\n",
        "    x = x.view(x.size(0), 1, 28, 28)\n",
        "    return x\n",
        "\n",
        "\n",
        "num_epochs = 101\n",
        "batch_size = 128\n",
        "learning_rate = 1e-3\n",
        "\n",
        "img_transform = transforms.Compose([\n",
        "    transforms.ToTensor()\n",
        "    # transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5))\n",
        "])\n",
        "\n",
        "dataset = MNIST('./data', transform=img_transform, download=True)\n",
        "dataloader = DataLoader(dataset, batch_size=batch_size, shuffle=True)\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fNYWMIGMvkFb",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 72
        },
        "outputId": "fc545b82-344b-486e-da5b-3385e8afc35f"
      },
      "source": [
        "class VAE(nn.Module):\n",
        "    def __init__(self):\n",
        "        super(VAE, self).__init__()\n",
        "\n",
        "        self.fc1 = nn.Linear(784, 400)\n",
        "        self.fc21 = nn.Linear(400, 20)\n",
        "        self.fc22 = nn.Linear(400, 20)\n",
        "        self.fc3 = nn.Linear(20, 400)\n",
        "        self.fc4 = nn.Linear(400, 784)\n",
        "\n",
        "    def encode(self, x):\n",
        "        h1 = F.relu(self.fc1(x))\n",
        "        return self.fc21(h1), self.fc22(h1)\n",
        "\n",
        "    def reparametrize(self, mu, logvar):\n",
        "        std = logvar.mul(0.5).exp_()\n",
        "        if torch.cuda.is_available():\n",
        "            eps = torch.cuda.FloatTensor(std.size()).normal_()\n",
        "        else:\n",
        "            eps = torch.FloatTensor(std.size()).normal_()\n",
        "        eps = Variable(eps)\n",
        "        return eps.mul(std).add_(mu)\n",
        "\n",
        "    def decode(self, z):\n",
        "        h3 = F.relu(self.fc3(z))\n",
        "        return F.sigmoid(self.fc4(h3))\n",
        "\n",
        "    def forward(self, x):\n",
        "        mu, logvar = self.encode(x)\n",
        "        z = self.reparametrize(mu, logvar)\n",
        "        return self.decode(z), mu, logvar\n",
        "\n",
        "\n",
        "model = VAE()\n",
        "if torch.cuda.is_available():\n",
        "    model.cuda()\n",
        "\n",
        "reconstruction_function = nn.MSELoss(size_average=False)\n",
        "\n",
        "\n",
        "def loss_function(recon_x, x, mu, logvar):\n",
        "    \"\"\"\n",
        "    recon_x: generating images\n",
        "    x: origin images\n",
        "    mu: latent mean\n",
        "    logvar: latent log variance\n",
        "    \"\"\"\n",
        "    BCE = reconstruction_function(recon_x, x)  # mse loss\n",
        "    # loss = 0.5 * sum(1 + log(sigma^2) - mu^2 - sigma^2)\n",
        "    KLD_element = mu.pow(2).add_(logvar.exp()).mul_(-1).add_(1).add_(logvar)\n",
        "    KLD = torch.sum(KLD_element).mul_(-0.5)\n",
        "    # KL divergence\n",
        "    return BCE + KLD\n",
        "\n",
        "\n",
        "optimizer = optim.Adam(model.parameters(), lr=1e-3)"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/torch/nn/_reduction.py:43: UserWarning: size_average and reduce args will be deprecated, please use reduction='sum' instead.\n",
            "  warnings.warn(warning.format(ret))\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "iK0vjXBwLGxE",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 72
        },
        "outputId": "9c9cb576-1936-4046-a19f-31ee23903047"
      },
      "source": [
        "class VAEPredicter(nn.Module):\n",
        "    def __init__(self):\n",
        "        super(VAEPredicter, self).__init__()\n",
        "\n",
        "        self.fc1 = nn.Linear(784, 400)\n",
        "        self.fc11 = nn.Linear(400, 400)\n",
        "        self.fc21 = nn.Linear(400, 20)\n",
        "        self.fc22 = nn.Linear(400, 20)\n",
        "        self.fc3 = nn.Linear(20, 400)\n",
        "        self.fc4 = nn.Linear(400, 784)\n",
        "\n",
        "    def encode(self, x):\n",
        "        h1 = F.relu(self.fc1(x))\n",
        "        h2 = F.relu(self.fc11(h1))\n",
        "        return self.fc21(h2), self.fc22(h2)\n",
        "\n",
        "    def reparametrize(self, mu, logvar):\n",
        "        std = logvar.mul(0.5).exp_()\n",
        "        if torch.cuda.is_available():\n",
        "            eps = torch.cuda.FloatTensor(std.size()).normal_()\n",
        "        else:\n",
        "            eps = torch.FloatTensor(std.size()).normal_()\n",
        "        eps = Variable(eps)\n",
        "        return eps.mul(std).add_(mu)\n",
        "\n",
        "\n",
        "    def forward(self, x):\n",
        "        mu, logvar = self.encode(x)\n",
        "        z = self.reparametrize(mu, logvar)\n",
        "        return z\n",
        "\n",
        "\n",
        "predModel = VAEPredicter()\n",
        "if torch.cuda.is_available():\n",
        "    model.cuda()\n",
        "\n",
        "predict_function = nn.MSELoss(size_average=False)\n",
        "\n",
        "\n",
        "def pred_loss_function(pred_z, target_z):#, mu, logvar):\n",
        "    \"\"\"\n",
        "    recon_x: generating images\n",
        "    x: origin images\n",
        "    mu: latent mean\n",
        "    logvar: latent log variance\n",
        "    \"\"\"\n",
        "    BCE = predict_function(pred_z, target_z)  # mse loss\n",
        "    # loss = 0.5 * sum(1 + log(sigma^2) - mu^2 - sigma^2)\n",
        "    #KLD_element = mu.pow(2).add_(logvar.exp()).mul_(-1).add_(1).add_(logvar)\n",
        "    #KLD = torch.sum(KLD_element).mul_(-0.5)\n",
        "    # KL divergence\n",
        "    return BCE\n",
        "\n",
        "\n",
        "optimizer = optim.Adam(model.parameters(), lr=1e-3)"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/torch/nn/_reduction.py:43: UserWarning: size_average and reduce args will be deprecated, please use reduction='sum' instead.\n",
            "  warnings.warn(warning.format(ret))\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3BlVeCd-1dbm",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "e91333e9-a3fa-4a0e-b108-5241ec2d5457"
      },
      "source": [
        "for epoch in range(num_epochs):\n",
        "    model.train()\n",
        "    train_loss = 0\n",
        "    for batch_idx, data in enumerate(dataloader):\n",
        "        img, _ = data\n",
        "        img = img.view(img.size(0), -1)\n",
        "        img = Variable(img)\n",
        "        if torch.cuda.is_available():\n",
        "            img = img.cuda()\n",
        "        optimizer.zero_grad()\n",
        "        recon_batch, mu, logvar = model(img)\n",
        "        loss = loss_function(recon_batch, img, mu, logvar)\n",
        "        loss.backward()\n",
        "        train_loss += loss.item()\n",
        "        optimizer.step()\n",
        "        if batch_idx % 100 == 0:\n",
        "            print('Train Epoch: {} [{}/{} ({:.0f}%)]\\tLoss: {:.6f}'.format(\n",
        "                epoch,\n",
        "                batch_idx * len(img),\n",
        "                len(dataloader.dataset), 100. * batch_idx / len(dataloader),\n",
        "                loss.item() / len(img)))\n",
        "\n",
        "    print('====> Epoch: {} Average loss: {:.4f}'.format(\n",
        "        epoch, train_loss / len(dataloader.dataset)))\n",
        "    if epoch % 10 == 0:\n",
        "        save = to_img(recon_batch.cpu().data)\n",
        "        save_image(save, './vae_img/image_{}.png'.format(epoch))\n",
        "model.train(mode=False)\n",
        "torch.save(model.state_dict(), './vae.pth')"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/torch/nn/functional.py:1351: UserWarning: nn.functional.sigmoid is deprecated. Use torch.sigmoid instead.\n",
            "  warnings.warn(\"nn.functional.sigmoid is deprecated. Use torch.sigmoid instead.\")\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Train Epoch: 0 [0/60000 (0%)]\tLoss: 185.769028\n",
            "Train Epoch: 0 [12800/60000 (21%)]\tLoss: 51.356354\n",
            "Train Epoch: 0 [25600/60000 (43%)]\tLoss: 42.840378\n",
            "Train Epoch: 0 [38400/60000 (64%)]\tLoss: 42.023727\n",
            "Train Epoch: 0 [51200/60000 (85%)]\tLoss: 38.964962\n",
            "====> Epoch: 0 Average loss: 45.6278\n",
            "Train Epoch: 1 [0/60000 (0%)]\tLoss: 36.925941\n",
            "Train Epoch: 1 [12800/60000 (21%)]\tLoss: 37.306335\n",
            "Train Epoch: 1 [25600/60000 (43%)]\tLoss: 34.015518\n",
            "Train Epoch: 1 [38400/60000 (64%)]\tLoss: 33.826256\n",
            "Train Epoch: 1 [51200/60000 (85%)]\tLoss: 33.360420\n",
            "====> Epoch: 1 Average loss: 35.0348\n",
            "Train Epoch: 2 [0/60000 (0%)]\tLoss: 35.772167\n",
            "Train Epoch: 2 [12800/60000 (21%)]\tLoss: 33.084648\n",
            "Train Epoch: 2 [25600/60000 (43%)]\tLoss: 33.256634\n",
            "Train Epoch: 2 [38400/60000 (64%)]\tLoss: 33.135281\n",
            "Train Epoch: 2 [51200/60000 (85%)]\tLoss: 33.024170\n",
            "====> Epoch: 2 Average loss: 33.1167\n",
            "Train Epoch: 3 [0/60000 (0%)]\tLoss: 33.344433\n",
            "Train Epoch: 3 [12800/60000 (21%)]\tLoss: 33.814194\n",
            "Train Epoch: 3 [25600/60000 (43%)]\tLoss: 32.679001\n",
            "Train Epoch: 3 [38400/60000 (64%)]\tLoss: 32.350327\n",
            "Train Epoch: 3 [51200/60000 (85%)]\tLoss: 31.784901\n",
            "====> Epoch: 3 Average loss: 32.2480\n",
            "Train Epoch: 4 [0/60000 (0%)]\tLoss: 32.543034\n",
            "Train Epoch: 4 [12800/60000 (21%)]\tLoss: 31.991508\n",
            "Train Epoch: 4 [25600/60000 (43%)]\tLoss: 31.822474\n",
            "Train Epoch: 4 [38400/60000 (64%)]\tLoss: 31.665108\n",
            "Train Epoch: 4 [51200/60000 (85%)]\tLoss: 29.637844\n",
            "====> Epoch: 4 Average loss: 31.7271\n",
            "Train Epoch: 5 [0/60000 (0%)]\tLoss: 32.159859\n",
            "Train Epoch: 5 [12800/60000 (21%)]\tLoss: 31.776587\n",
            "Train Epoch: 5 [25600/60000 (43%)]\tLoss: 30.834084\n",
            "Train Epoch: 5 [38400/60000 (64%)]\tLoss: 30.826614\n",
            "Train Epoch: 5 [51200/60000 (85%)]\tLoss: 31.453693\n",
            "====> Epoch: 5 Average loss: 31.3328\n",
            "Train Epoch: 6 [0/60000 (0%)]\tLoss: 30.796047\n",
            "Train Epoch: 6 [12800/60000 (21%)]\tLoss: 30.646477\n",
            "Train Epoch: 6 [25600/60000 (43%)]\tLoss: 31.661589\n",
            "Train Epoch: 6 [38400/60000 (64%)]\tLoss: 31.666145\n",
            "Train Epoch: 6 [51200/60000 (85%)]\tLoss: 30.995716\n",
            "====> Epoch: 6 Average loss: 31.0881\n",
            "Train Epoch: 7 [0/60000 (0%)]\tLoss: 31.112671\n",
            "Train Epoch: 7 [12800/60000 (21%)]\tLoss: 31.779739\n",
            "Train Epoch: 7 [25600/60000 (43%)]\tLoss: 30.743019\n",
            "Train Epoch: 7 [38400/60000 (64%)]\tLoss: 30.121675\n",
            "Train Epoch: 7 [51200/60000 (85%)]\tLoss: 29.932785\n",
            "====> Epoch: 7 Average loss: 30.9127\n",
            "Train Epoch: 8 [0/60000 (0%)]\tLoss: 30.340933\n",
            "Train Epoch: 8 [12800/60000 (21%)]\tLoss: 31.212946\n",
            "Train Epoch: 8 [25600/60000 (43%)]\tLoss: 29.984873\n",
            "Train Epoch: 8 [38400/60000 (64%)]\tLoss: 29.879360\n",
            "Train Epoch: 8 [51200/60000 (85%)]\tLoss: 30.864462\n",
            "====> Epoch: 8 Average loss: 30.7376\n",
            "Train Epoch: 9 [0/60000 (0%)]\tLoss: 30.917217\n",
            "Train Epoch: 9 [12800/60000 (21%)]\tLoss: 30.623062\n",
            "Train Epoch: 9 [25600/60000 (43%)]\tLoss: 30.701416\n",
            "Train Epoch: 9 [38400/60000 (64%)]\tLoss: 30.438185\n",
            "Train Epoch: 9 [51200/60000 (85%)]\tLoss: 30.024815\n",
            "====> Epoch: 9 Average loss: 30.5877\n",
            "Train Epoch: 10 [0/60000 (0%)]\tLoss: 30.744398\n",
            "Train Epoch: 10 [12800/60000 (21%)]\tLoss: 30.180511\n",
            "Train Epoch: 10 [25600/60000 (43%)]\tLoss: 30.426521\n",
            "Train Epoch: 10 [38400/60000 (64%)]\tLoss: 29.770182\n",
            "Train Epoch: 10 [51200/60000 (85%)]\tLoss: 30.044453\n",
            "====> Epoch: 10 Average loss: 30.4897\n",
            "Train Epoch: 11 [0/60000 (0%)]\tLoss: 30.538836\n",
            "Train Epoch: 11 [12800/60000 (21%)]\tLoss: 30.874836\n",
            "Train Epoch: 11 [25600/60000 (43%)]\tLoss: 30.137213\n",
            "Train Epoch: 11 [38400/60000 (64%)]\tLoss: 30.933533\n",
            "Train Epoch: 11 [51200/60000 (85%)]\tLoss: 30.018261\n",
            "====> Epoch: 11 Average loss: 30.3696\n",
            "Train Epoch: 12 [0/60000 (0%)]\tLoss: 29.996197\n",
            "Train Epoch: 12 [12800/60000 (21%)]\tLoss: 30.573566\n",
            "Train Epoch: 12 [25600/60000 (43%)]\tLoss: 30.532036\n",
            "Train Epoch: 12 [38400/60000 (64%)]\tLoss: 29.477333\n",
            "Train Epoch: 12 [51200/60000 (85%)]\tLoss: 30.430149\n",
            "====> Epoch: 12 Average loss: 30.2800\n",
            "Train Epoch: 13 [0/60000 (0%)]\tLoss: 30.021545\n",
            "Train Epoch: 13 [12800/60000 (21%)]\tLoss: 30.432468\n",
            "Train Epoch: 13 [25600/60000 (43%)]\tLoss: 31.591780\n",
            "Train Epoch: 13 [38400/60000 (64%)]\tLoss: 29.586815\n",
            "Train Epoch: 13 [51200/60000 (85%)]\tLoss: 30.860474\n",
            "====> Epoch: 13 Average loss: 30.1857\n",
            "Train Epoch: 14 [0/60000 (0%)]\tLoss: 30.652020\n",
            "Train Epoch: 14 [12800/60000 (21%)]\tLoss: 30.961897\n",
            "Train Epoch: 14 [25600/60000 (43%)]\tLoss: 30.182236\n",
            "Train Epoch: 14 [38400/60000 (64%)]\tLoss: 30.554684\n",
            "Train Epoch: 14 [51200/60000 (85%)]\tLoss: 29.394753\n",
            "====> Epoch: 14 Average loss: 30.0878\n",
            "Train Epoch: 15 [0/60000 (0%)]\tLoss: 29.671860\n",
            "Train Epoch: 15 [12800/60000 (21%)]\tLoss: 29.546003\n",
            "Train Epoch: 15 [25600/60000 (43%)]\tLoss: 29.393829\n",
            "Train Epoch: 15 [38400/60000 (64%)]\tLoss: 29.543411\n",
            "Train Epoch: 15 [51200/60000 (85%)]\tLoss: 30.657009\n",
            "====> Epoch: 15 Average loss: 30.0121\n",
            "Train Epoch: 16 [0/60000 (0%)]\tLoss: 30.561211\n",
            "Train Epoch: 16 [12800/60000 (21%)]\tLoss: 30.233850\n",
            "Train Epoch: 16 [25600/60000 (43%)]\tLoss: 30.254740\n",
            "Train Epoch: 16 [38400/60000 (64%)]\tLoss: 31.155949\n",
            "Train Epoch: 16 [51200/60000 (85%)]\tLoss: 29.880566\n",
            "====> Epoch: 16 Average loss: 29.9393\n",
            "Train Epoch: 17 [0/60000 (0%)]\tLoss: 30.090433\n",
            "Train Epoch: 17 [12800/60000 (21%)]\tLoss: 30.034986\n",
            "Train Epoch: 17 [25600/60000 (43%)]\tLoss: 29.645420\n",
            "Train Epoch: 17 [38400/60000 (64%)]\tLoss: 29.798458\n",
            "Train Epoch: 17 [51200/60000 (85%)]\tLoss: 29.932980\n",
            "====> Epoch: 17 Average loss: 29.8764\n",
            "Train Epoch: 18 [0/60000 (0%)]\tLoss: 30.384468\n",
            "Train Epoch: 18 [12800/60000 (21%)]\tLoss: 28.933681\n",
            "Train Epoch: 18 [25600/60000 (43%)]\tLoss: 29.541697\n",
            "Train Epoch: 18 [38400/60000 (64%)]\tLoss: 30.850941\n",
            "Train Epoch: 18 [51200/60000 (85%)]\tLoss: 30.690908\n",
            "====> Epoch: 18 Average loss: 29.7993\n",
            "Train Epoch: 19 [0/60000 (0%)]\tLoss: 29.385687\n",
            "Train Epoch: 19 [12800/60000 (21%)]\tLoss: 29.014275\n",
            "Train Epoch: 19 [25600/60000 (43%)]\tLoss: 29.787128\n",
            "Train Epoch: 19 [38400/60000 (64%)]\tLoss: 29.735134\n",
            "Train Epoch: 19 [51200/60000 (85%)]\tLoss: 29.511425\n",
            "====> Epoch: 19 Average loss: 29.7434\n",
            "Train Epoch: 20 [0/60000 (0%)]\tLoss: 28.909222\n",
            "Train Epoch: 20 [12800/60000 (21%)]\tLoss: 30.108549\n",
            "Train Epoch: 20 [25600/60000 (43%)]\tLoss: 29.442635\n",
            "Train Epoch: 20 [38400/60000 (64%)]\tLoss: 29.323151\n",
            "Train Epoch: 20 [51200/60000 (85%)]\tLoss: 30.594601\n",
            "====> Epoch: 20 Average loss: 29.7192\n",
            "Train Epoch: 21 [0/60000 (0%)]\tLoss: 29.292879\n",
            "Train Epoch: 21 [12800/60000 (21%)]\tLoss: 30.034277\n",
            "Train Epoch: 21 [25600/60000 (43%)]\tLoss: 29.076408\n",
            "Train Epoch: 21 [38400/60000 (64%)]\tLoss: 30.561199\n",
            "Train Epoch: 21 [51200/60000 (85%)]\tLoss: 29.040966\n",
            "====> Epoch: 21 Average loss: 29.6539\n",
            "Train Epoch: 22 [0/60000 (0%)]\tLoss: 29.052614\n",
            "Train Epoch: 22 [12800/60000 (21%)]\tLoss: 28.703339\n",
            "Train Epoch: 22 [25600/60000 (43%)]\tLoss: 29.467855\n",
            "Train Epoch: 22 [38400/60000 (64%)]\tLoss: 29.118908\n",
            "Train Epoch: 22 [51200/60000 (85%)]\tLoss: 28.613138\n",
            "====> Epoch: 22 Average loss: 29.6129\n",
            "Train Epoch: 23 [0/60000 (0%)]\tLoss: 28.939037\n",
            "Train Epoch: 23 [12800/60000 (21%)]\tLoss: 28.122154\n",
            "Train Epoch: 23 [25600/60000 (43%)]\tLoss: 29.684631\n",
            "Train Epoch: 23 [38400/60000 (64%)]\tLoss: 28.445721\n",
            "Train Epoch: 23 [51200/60000 (85%)]\tLoss: 29.003143\n",
            "====> Epoch: 23 Average loss: 29.5735\n",
            "Train Epoch: 24 [0/60000 (0%)]\tLoss: 30.398407\n",
            "Train Epoch: 24 [12800/60000 (21%)]\tLoss: 28.258591\n",
            "Train Epoch: 24 [25600/60000 (43%)]\tLoss: 30.064034\n",
            "Train Epoch: 24 [38400/60000 (64%)]\tLoss: 29.552090\n",
            "Train Epoch: 24 [51200/60000 (85%)]\tLoss: 29.621641\n",
            "====> Epoch: 24 Average loss: 29.5006\n",
            "Train Epoch: 25 [0/60000 (0%)]\tLoss: 29.323675\n",
            "Train Epoch: 25 [12800/60000 (21%)]\tLoss: 30.473797\n",
            "Train Epoch: 25 [25600/60000 (43%)]\tLoss: 29.760599\n",
            "Train Epoch: 25 [38400/60000 (64%)]\tLoss: 30.878763\n",
            "Train Epoch: 25 [51200/60000 (85%)]\tLoss: 29.277786\n",
            "====> Epoch: 25 Average loss: 29.4567\n",
            "Train Epoch: 26 [0/60000 (0%)]\tLoss: 28.372410\n",
            "Train Epoch: 26 [12800/60000 (21%)]\tLoss: 29.512856\n",
            "Train Epoch: 26 [25600/60000 (43%)]\tLoss: 28.613104\n",
            "Train Epoch: 26 [38400/60000 (64%)]\tLoss: 29.063606\n",
            "Train Epoch: 26 [51200/60000 (85%)]\tLoss: 30.293945\n",
            "====> Epoch: 26 Average loss: 29.4193\n",
            "Train Epoch: 27 [0/60000 (0%)]\tLoss: 29.945147\n",
            "Train Epoch: 27 [12800/60000 (21%)]\tLoss: 29.801373\n",
            "Train Epoch: 27 [25600/60000 (43%)]\tLoss: 28.817081\n",
            "Train Epoch: 27 [38400/60000 (64%)]\tLoss: 29.364389\n",
            "Train Epoch: 27 [51200/60000 (85%)]\tLoss: 29.823235\n",
            "====> Epoch: 27 Average loss: 29.3818\n",
            "Train Epoch: 28 [0/60000 (0%)]\tLoss: 30.392033\n",
            "Train Epoch: 28 [12800/60000 (21%)]\tLoss: 30.303112\n",
            "Train Epoch: 28 [25600/60000 (43%)]\tLoss: 29.551443\n",
            "Train Epoch: 28 [38400/60000 (64%)]\tLoss: 28.497766\n",
            "Train Epoch: 28 [51200/60000 (85%)]\tLoss: 30.176552\n",
            "====> Epoch: 28 Average loss: 29.3378\n",
            "Train Epoch: 29 [0/60000 (0%)]\tLoss: 29.518274\n",
            "Train Epoch: 29 [12800/60000 (21%)]\tLoss: 29.263737\n",
            "Train Epoch: 29 [25600/60000 (43%)]\tLoss: 29.009134\n",
            "Train Epoch: 29 [38400/60000 (64%)]\tLoss: 28.463303\n",
            "Train Epoch: 29 [51200/60000 (85%)]\tLoss: 28.454031\n",
            "====> Epoch: 29 Average loss: 29.3207\n",
            "Train Epoch: 30 [0/60000 (0%)]\tLoss: 29.709719\n",
            "Train Epoch: 30 [12800/60000 (21%)]\tLoss: 29.746960\n",
            "Train Epoch: 30 [25600/60000 (43%)]\tLoss: 29.814966\n",
            "Train Epoch: 30 [38400/60000 (64%)]\tLoss: 28.062744\n",
            "Train Epoch: 30 [51200/60000 (85%)]\tLoss: 29.215508\n",
            "====> Epoch: 30 Average loss: 29.2683\n",
            "Train Epoch: 31 [0/60000 (0%)]\tLoss: 28.770866\n",
            "Train Epoch: 31 [12800/60000 (21%)]\tLoss: 29.159594\n",
            "Train Epoch: 31 [25600/60000 (43%)]\tLoss: 29.595512\n",
            "Train Epoch: 31 [38400/60000 (64%)]\tLoss: 30.361214\n",
            "Train Epoch: 31 [51200/60000 (85%)]\tLoss: 30.112825\n",
            "====> Epoch: 31 Average loss: 29.2486\n",
            "Train Epoch: 32 [0/60000 (0%)]\tLoss: 28.274563\n",
            "Train Epoch: 32 [12800/60000 (21%)]\tLoss: 30.036251\n",
            "Train Epoch: 32 [25600/60000 (43%)]\tLoss: 30.111523\n",
            "Train Epoch: 32 [38400/60000 (64%)]\tLoss: 28.583559\n",
            "Train Epoch: 32 [51200/60000 (85%)]\tLoss: 28.711449\n",
            "====> Epoch: 32 Average loss: 29.1984\n",
            "Train Epoch: 33 [0/60000 (0%)]\tLoss: 28.518196\n",
            "Train Epoch: 33 [12800/60000 (21%)]\tLoss: 29.033665\n",
            "Train Epoch: 33 [25600/60000 (43%)]\tLoss: 30.200514\n",
            "Train Epoch: 33 [38400/60000 (64%)]\tLoss: 28.785355\n",
            "Train Epoch: 33 [51200/60000 (85%)]\tLoss: 28.862347\n",
            "====> Epoch: 33 Average loss: 29.1963\n",
            "Train Epoch: 34 [0/60000 (0%)]\tLoss: 30.064310\n",
            "Train Epoch: 34 [12800/60000 (21%)]\tLoss: 30.469360\n",
            "Train Epoch: 34 [25600/60000 (43%)]\tLoss: 29.572006\n",
            "Train Epoch: 34 [38400/60000 (64%)]\tLoss: 29.331766\n",
            "Train Epoch: 34 [51200/60000 (85%)]\tLoss: 29.715809\n",
            "====> Epoch: 34 Average loss: 29.1479\n",
            "Train Epoch: 35 [0/60000 (0%)]\tLoss: 28.717903\n",
            "Train Epoch: 35 [12800/60000 (21%)]\tLoss: 30.071449\n",
            "Train Epoch: 35 [25600/60000 (43%)]\tLoss: 29.745443\n",
            "Train Epoch: 35 [38400/60000 (64%)]\tLoss: 27.853649\n",
            "Train Epoch: 35 [51200/60000 (85%)]\tLoss: 28.676889\n",
            "====> Epoch: 35 Average loss: 29.1069\n",
            "Train Epoch: 36 [0/60000 (0%)]\tLoss: 29.066776\n",
            "Train Epoch: 36 [12800/60000 (21%)]\tLoss: 29.421646\n",
            "Train Epoch: 36 [25600/60000 (43%)]\tLoss: 28.570297\n",
            "Train Epoch: 36 [38400/60000 (64%)]\tLoss: 28.508032\n",
            "Train Epoch: 36 [51200/60000 (85%)]\tLoss: 29.069218\n",
            "====> Epoch: 36 Average loss: 29.0781\n",
            "Train Epoch: 37 [0/60000 (0%)]\tLoss: 28.969093\n",
            "Train Epoch: 37 [12800/60000 (21%)]\tLoss: 30.122051\n",
            "Train Epoch: 37 [25600/60000 (43%)]\tLoss: 28.265152\n",
            "Train Epoch: 37 [38400/60000 (64%)]\tLoss: 30.560272\n",
            "Train Epoch: 37 [51200/60000 (85%)]\tLoss: 30.649742\n",
            "====> Epoch: 37 Average loss: 29.0612\n",
            "Train Epoch: 38 [0/60000 (0%)]\tLoss: 27.282856\n",
            "Train Epoch: 38 [12800/60000 (21%)]\tLoss: 30.225023\n",
            "Train Epoch: 38 [25600/60000 (43%)]\tLoss: 28.887932\n",
            "Train Epoch: 38 [38400/60000 (64%)]\tLoss: 28.049616\n",
            "Train Epoch: 38 [51200/60000 (85%)]\tLoss: 29.060432\n",
            "====> Epoch: 38 Average loss: 29.0183\n",
            "Train Epoch: 39 [0/60000 (0%)]\tLoss: 29.711311\n",
            "Train Epoch: 39 [12800/60000 (21%)]\tLoss: 28.626074\n",
            "Train Epoch: 39 [25600/60000 (43%)]\tLoss: 28.783962\n",
            "Train Epoch: 39 [38400/60000 (64%)]\tLoss: 27.757954\n",
            "Train Epoch: 39 [51200/60000 (85%)]\tLoss: 27.544781\n",
            "====> Epoch: 39 Average loss: 29.0205\n",
            "Train Epoch: 40 [0/60000 (0%)]\tLoss: 29.677860\n",
            "Train Epoch: 40 [12800/60000 (21%)]\tLoss: 29.119799\n",
            "Train Epoch: 40 [25600/60000 (43%)]\tLoss: 30.238823\n",
            "Train Epoch: 40 [38400/60000 (64%)]\tLoss: 29.538696\n",
            "Train Epoch: 40 [51200/60000 (85%)]\tLoss: 29.300083\n",
            "====> Epoch: 40 Average loss: 29.0108\n",
            "Train Epoch: 41 [0/60000 (0%)]\tLoss: 29.546875\n",
            "Train Epoch: 41 [12800/60000 (21%)]\tLoss: 28.941732\n",
            "Train Epoch: 41 [25600/60000 (43%)]\tLoss: 28.318583\n",
            "Train Epoch: 41 [38400/60000 (64%)]\tLoss: 29.518082\n",
            "Train Epoch: 41 [51200/60000 (85%)]\tLoss: 30.040657\n",
            "====> Epoch: 41 Average loss: 28.9730\n",
            "Train Epoch: 42 [0/60000 (0%)]\tLoss: 29.662769\n",
            "Train Epoch: 42 [12800/60000 (21%)]\tLoss: 29.325539\n",
            "Train Epoch: 42 [25600/60000 (43%)]\tLoss: 29.463848\n",
            "Train Epoch: 42 [38400/60000 (64%)]\tLoss: 28.694805\n",
            "Train Epoch: 42 [51200/60000 (85%)]\tLoss: 28.747433\n",
            "====> Epoch: 42 Average loss: 28.9633\n",
            "Train Epoch: 43 [0/60000 (0%)]\tLoss: 29.331753\n",
            "Train Epoch: 43 [12800/60000 (21%)]\tLoss: 28.206665\n",
            "Train Epoch: 43 [25600/60000 (43%)]\tLoss: 29.169964\n",
            "Train Epoch: 43 [38400/60000 (64%)]\tLoss: 28.709476\n",
            "Train Epoch: 43 [51200/60000 (85%)]\tLoss: 30.134399\n",
            "====> Epoch: 43 Average loss: 28.9338\n",
            "Train Epoch: 44 [0/60000 (0%)]\tLoss: 28.109079\n",
            "Train Epoch: 44 [12800/60000 (21%)]\tLoss: 29.207657\n",
            "Train Epoch: 44 [25600/60000 (43%)]\tLoss: 30.151007\n",
            "Train Epoch: 44 [38400/60000 (64%)]\tLoss: 28.551270\n",
            "Train Epoch: 44 [51200/60000 (85%)]\tLoss: 28.204445\n",
            "====> Epoch: 44 Average loss: 28.9186\n",
            "Train Epoch: 45 [0/60000 (0%)]\tLoss: 29.135784\n",
            "Train Epoch: 45 [12800/60000 (21%)]\tLoss: 29.239048\n",
            "Train Epoch: 45 [25600/60000 (43%)]\tLoss: 28.263783\n",
            "Train Epoch: 45 [38400/60000 (64%)]\tLoss: 29.212574\n",
            "Train Epoch: 45 [51200/60000 (85%)]\tLoss: 30.676495\n",
            "====> Epoch: 45 Average loss: 28.8912\n",
            "Train Epoch: 46 [0/60000 (0%)]\tLoss: 30.337490\n",
            "Train Epoch: 46 [12800/60000 (21%)]\tLoss: 27.867344\n",
            "Train Epoch: 46 [25600/60000 (43%)]\tLoss: 28.964344\n",
            "Train Epoch: 46 [38400/60000 (64%)]\tLoss: 29.379333\n",
            "Train Epoch: 46 [51200/60000 (85%)]\tLoss: 28.993290\n",
            "====> Epoch: 46 Average loss: 28.8634\n",
            "Train Epoch: 47 [0/60000 (0%)]\tLoss: 29.303049\n",
            "Train Epoch: 47 [12800/60000 (21%)]\tLoss: 29.275055\n",
            "Train Epoch: 47 [25600/60000 (43%)]\tLoss: 28.340639\n",
            "Train Epoch: 47 [38400/60000 (64%)]\tLoss: 30.200268\n",
            "Train Epoch: 47 [51200/60000 (85%)]\tLoss: 29.106682\n",
            "====> Epoch: 47 Average loss: 28.8345\n",
            "Train Epoch: 48 [0/60000 (0%)]\tLoss: 27.830418\n",
            "Train Epoch: 48 [12800/60000 (21%)]\tLoss: 28.107172\n",
            "Train Epoch: 48 [25600/60000 (43%)]\tLoss: 27.542919\n",
            "Train Epoch: 48 [38400/60000 (64%)]\tLoss: 28.442677\n",
            "Train Epoch: 48 [51200/60000 (85%)]\tLoss: 29.769243\n",
            "====> Epoch: 48 Average loss: 28.8090\n",
            "Train Epoch: 49 [0/60000 (0%)]\tLoss: 29.098089\n",
            "Train Epoch: 49 [12800/60000 (21%)]\tLoss: 28.347153\n",
            "Train Epoch: 49 [25600/60000 (43%)]\tLoss: 27.102760\n",
            "Train Epoch: 49 [38400/60000 (64%)]\tLoss: 29.126705\n",
            "Train Epoch: 49 [51200/60000 (85%)]\tLoss: 28.171938\n",
            "====> Epoch: 49 Average loss: 28.7937\n",
            "Train Epoch: 50 [0/60000 (0%)]\tLoss: 29.229725\n",
            "Train Epoch: 50 [12800/60000 (21%)]\tLoss: 30.272839\n",
            "Train Epoch: 50 [25600/60000 (43%)]\tLoss: 28.873196\n",
            "Train Epoch: 50 [38400/60000 (64%)]\tLoss: 28.963634\n",
            "Train Epoch: 50 [51200/60000 (85%)]\tLoss: 28.110798\n",
            "====> Epoch: 50 Average loss: 28.7769\n",
            "Train Epoch: 51 [0/60000 (0%)]\tLoss: 27.892948\n",
            "Train Epoch: 51 [12800/60000 (21%)]\tLoss: 28.466053\n",
            "Train Epoch: 51 [25600/60000 (43%)]\tLoss: 28.725422\n",
            "Train Epoch: 51 [38400/60000 (64%)]\tLoss: 29.420067\n",
            "Train Epoch: 51 [51200/60000 (85%)]\tLoss: 27.598734\n",
            "====> Epoch: 51 Average loss: 28.7686\n",
            "Train Epoch: 52 [0/60000 (0%)]\tLoss: 27.520420\n",
            "Train Epoch: 52 [12800/60000 (21%)]\tLoss: 29.349457\n",
            "Train Epoch: 52 [25600/60000 (43%)]\tLoss: 29.656860\n",
            "Train Epoch: 52 [38400/60000 (64%)]\tLoss: 29.106606\n",
            "Train Epoch: 52 [51200/60000 (85%)]\tLoss: 29.589363\n",
            "====> Epoch: 52 Average loss: 28.7253\n",
            "Train Epoch: 53 [0/60000 (0%)]\tLoss: 29.268343\n",
            "Train Epoch: 53 [12800/60000 (21%)]\tLoss: 28.965776\n",
            "Train Epoch: 53 [25600/60000 (43%)]\tLoss: 28.112873\n",
            "Train Epoch: 53 [38400/60000 (64%)]\tLoss: 29.034241\n",
            "Train Epoch: 53 [51200/60000 (85%)]\tLoss: 28.375391\n",
            "====> Epoch: 53 Average loss: 28.7115\n",
            "Train Epoch: 54 [0/60000 (0%)]\tLoss: 28.518105\n",
            "Train Epoch: 54 [12800/60000 (21%)]\tLoss: 28.183945\n",
            "Train Epoch: 54 [25600/60000 (43%)]\tLoss: 27.654165\n",
            "Train Epoch: 54 [38400/60000 (64%)]\tLoss: 28.311169\n",
            "Train Epoch: 54 [51200/60000 (85%)]\tLoss: 28.953978\n",
            "====> Epoch: 54 Average loss: 28.6930\n",
            "Train Epoch: 55 [0/60000 (0%)]\tLoss: 27.994473\n",
            "Train Epoch: 55 [12800/60000 (21%)]\tLoss: 28.765743\n",
            "Train Epoch: 55 [25600/60000 (43%)]\tLoss: 29.398720\n",
            "Train Epoch: 55 [38400/60000 (64%)]\tLoss: 29.726402\n",
            "Train Epoch: 55 [51200/60000 (85%)]\tLoss: 28.352932\n",
            "====> Epoch: 55 Average loss: 28.6956\n",
            "Train Epoch: 56 [0/60000 (0%)]\tLoss: 28.191401\n",
            "Train Epoch: 56 [12800/60000 (21%)]\tLoss: 28.786053\n",
            "Train Epoch: 56 [25600/60000 (43%)]\tLoss: 28.335415\n",
            "Train Epoch: 56 [38400/60000 (64%)]\tLoss: 26.882805\n",
            "Train Epoch: 56 [51200/60000 (85%)]\tLoss: 28.284588\n",
            "====> Epoch: 56 Average loss: 28.6687\n",
            "Train Epoch: 57 [0/60000 (0%)]\tLoss: 28.798563\n",
            "Train Epoch: 57 [12800/60000 (21%)]\tLoss: 28.194641\n",
            "Train Epoch: 57 [25600/60000 (43%)]\tLoss: 28.995449\n",
            "Train Epoch: 57 [38400/60000 (64%)]\tLoss: 29.294853\n",
            "Train Epoch: 57 [51200/60000 (85%)]\tLoss: 28.538441\n",
            "====> Epoch: 57 Average loss: 28.6690\n",
            "Train Epoch: 58 [0/60000 (0%)]\tLoss: 29.409897\n",
            "Train Epoch: 58 [12800/60000 (21%)]\tLoss: 29.197617\n",
            "Train Epoch: 58 [25600/60000 (43%)]\tLoss: 28.578913\n",
            "Train Epoch: 58 [38400/60000 (64%)]\tLoss: 28.723875\n",
            "Train Epoch: 58 [51200/60000 (85%)]\tLoss: 28.929241\n",
            "====> Epoch: 58 Average loss: 28.6337\n",
            "Train Epoch: 59 [0/60000 (0%)]\tLoss: 28.232613\n",
            "Train Epoch: 59 [12800/60000 (21%)]\tLoss: 28.166262\n",
            "Train Epoch: 59 [25600/60000 (43%)]\tLoss: 29.221516\n",
            "Train Epoch: 59 [38400/60000 (64%)]\tLoss: 28.385118\n",
            "Train Epoch: 59 [51200/60000 (85%)]\tLoss: 29.712149\n",
            "====> Epoch: 59 Average loss: 28.6324\n",
            "Train Epoch: 60 [0/60000 (0%)]\tLoss: 28.379307\n",
            "Train Epoch: 60 [12800/60000 (21%)]\tLoss: 29.204243\n",
            "Train Epoch: 60 [25600/60000 (43%)]\tLoss: 29.182674\n",
            "Train Epoch: 60 [38400/60000 (64%)]\tLoss: 28.430891\n",
            "Train Epoch: 60 [51200/60000 (85%)]\tLoss: 29.200451\n",
            "====> Epoch: 60 Average loss: 28.6104\n",
            "Train Epoch: 61 [0/60000 (0%)]\tLoss: 28.893366\n",
            "Train Epoch: 61 [12800/60000 (21%)]\tLoss: 28.353161\n",
            "Train Epoch: 61 [25600/60000 (43%)]\tLoss: 30.102287\n",
            "Train Epoch: 61 [38400/60000 (64%)]\tLoss: 29.051016\n",
            "Train Epoch: 61 [51200/60000 (85%)]\tLoss: 28.522888\n",
            "====> Epoch: 61 Average loss: 28.6103\n",
            "Train Epoch: 62 [0/60000 (0%)]\tLoss: 28.576000\n",
            "Train Epoch: 62 [12800/60000 (21%)]\tLoss: 28.580185\n",
            "Train Epoch: 62 [25600/60000 (43%)]\tLoss: 29.360640\n",
            "Train Epoch: 62 [38400/60000 (64%)]\tLoss: 28.124929\n",
            "Train Epoch: 62 [51200/60000 (85%)]\tLoss: 29.147532\n",
            "====> Epoch: 62 Average loss: 28.5820\n",
            "Train Epoch: 63 [0/60000 (0%)]\tLoss: 27.870083\n",
            "Train Epoch: 63 [12800/60000 (21%)]\tLoss: 27.494122\n",
            "Train Epoch: 63 [25600/60000 (43%)]\tLoss: 27.815392\n",
            "Train Epoch: 63 [38400/60000 (64%)]\tLoss: 28.976864\n",
            "Train Epoch: 63 [51200/60000 (85%)]\tLoss: 28.991659\n",
            "====> Epoch: 63 Average loss: 28.5870\n",
            "Train Epoch: 64 [0/60000 (0%)]\tLoss: 28.517834\n",
            "Train Epoch: 64 [12800/60000 (21%)]\tLoss: 28.793791\n",
            "Train Epoch: 64 [25600/60000 (43%)]\tLoss: 30.013046\n",
            "Train Epoch: 64 [38400/60000 (64%)]\tLoss: 28.922373\n",
            "Train Epoch: 64 [51200/60000 (85%)]\tLoss: 29.386021\n",
            "====> Epoch: 64 Average loss: 28.5746\n",
            "Train Epoch: 65 [0/60000 (0%)]\tLoss: 27.694260\n",
            "Train Epoch: 65 [12800/60000 (21%)]\tLoss: 29.039753\n",
            "Train Epoch: 65 [25600/60000 (43%)]\tLoss: 28.949600\n",
            "Train Epoch: 65 [38400/60000 (64%)]\tLoss: 28.377438\n",
            "Train Epoch: 65 [51200/60000 (85%)]\tLoss: 29.018169\n",
            "====> Epoch: 65 Average loss: 28.5507\n",
            "Train Epoch: 66 [0/60000 (0%)]\tLoss: 27.767061\n",
            "Train Epoch: 66 [12800/60000 (21%)]\tLoss: 28.885380\n",
            "Train Epoch: 66 [25600/60000 (43%)]\tLoss: 27.252670\n",
            "Train Epoch: 66 [38400/60000 (64%)]\tLoss: 28.382036\n",
            "Train Epoch: 66 [51200/60000 (85%)]\tLoss: 29.199738\n",
            "====> Epoch: 66 Average loss: 28.5161\n",
            "Train Epoch: 67 [0/60000 (0%)]\tLoss: 26.966625\n",
            "Train Epoch: 67 [12800/60000 (21%)]\tLoss: 28.032635\n",
            "Train Epoch: 67 [25600/60000 (43%)]\tLoss: 28.903778\n",
            "Train Epoch: 67 [38400/60000 (64%)]\tLoss: 28.079720\n",
            "Train Epoch: 67 [51200/60000 (85%)]\tLoss: 28.504160\n",
            "====> Epoch: 67 Average loss: 28.5058\n",
            "Train Epoch: 68 [0/60000 (0%)]\tLoss: 29.017433\n",
            "Train Epoch: 68 [12800/60000 (21%)]\tLoss: 27.766775\n",
            "Train Epoch: 68 [25600/60000 (43%)]\tLoss: 28.743568\n",
            "Train Epoch: 68 [38400/60000 (64%)]\tLoss: 27.293373\n",
            "Train Epoch: 68 [51200/60000 (85%)]\tLoss: 26.988216\n",
            "====> Epoch: 68 Average loss: 28.4948\n",
            "Train Epoch: 69 [0/60000 (0%)]\tLoss: 28.173428\n",
            "Train Epoch: 69 [12800/60000 (21%)]\tLoss: 28.299643\n",
            "Train Epoch: 69 [25600/60000 (43%)]\tLoss: 28.749954\n",
            "Train Epoch: 69 [38400/60000 (64%)]\tLoss: 29.433420\n",
            "Train Epoch: 69 [51200/60000 (85%)]\tLoss: 28.124512\n",
            "====> Epoch: 69 Average loss: 28.5127\n",
            "Train Epoch: 70 [0/60000 (0%)]\tLoss: 28.110085\n",
            "Train Epoch: 70 [12800/60000 (21%)]\tLoss: 28.475861\n",
            "Train Epoch: 70 [25600/60000 (43%)]\tLoss: 28.246525\n",
            "Train Epoch: 70 [38400/60000 (64%)]\tLoss: 28.695894\n",
            "Train Epoch: 70 [51200/60000 (85%)]\tLoss: 27.686983\n",
            "====> Epoch: 70 Average loss: 28.4839\n",
            "Train Epoch: 71 [0/60000 (0%)]\tLoss: 28.069370\n",
            "Train Epoch: 71 [12800/60000 (21%)]\tLoss: 29.092474\n",
            "Train Epoch: 71 [25600/60000 (43%)]\tLoss: 27.401901\n",
            "Train Epoch: 71 [38400/60000 (64%)]\tLoss: 28.713890\n",
            "Train Epoch: 71 [51200/60000 (85%)]\tLoss: 28.235901\n",
            "====> Epoch: 71 Average loss: 28.4899\n",
            "Train Epoch: 72 [0/60000 (0%)]\tLoss: 28.051571\n",
            "Train Epoch: 72 [12800/60000 (21%)]\tLoss: 27.900784\n",
            "Train Epoch: 72 [25600/60000 (43%)]\tLoss: 27.778709\n",
            "Train Epoch: 72 [38400/60000 (64%)]\tLoss: 28.291767\n",
            "Train Epoch: 72 [51200/60000 (85%)]\tLoss: 27.429600\n",
            "====> Epoch: 72 Average loss: 28.4520\n",
            "Train Epoch: 73 [0/60000 (0%)]\tLoss: 27.699108\n",
            "Train Epoch: 73 [12800/60000 (21%)]\tLoss: 28.283264\n",
            "Train Epoch: 73 [25600/60000 (43%)]\tLoss: 29.283199\n",
            "Train Epoch: 73 [38400/60000 (64%)]\tLoss: 28.012756\n",
            "Train Epoch: 73 [51200/60000 (85%)]\tLoss: 29.171799\n",
            "====> Epoch: 73 Average loss: 28.4480\n",
            "Train Epoch: 74 [0/60000 (0%)]\tLoss: 28.518194\n",
            "Train Epoch: 74 [12800/60000 (21%)]\tLoss: 28.570217\n",
            "Train Epoch: 74 [25600/60000 (43%)]\tLoss: 29.265511\n",
            "Train Epoch: 74 [38400/60000 (64%)]\tLoss: 27.538006\n",
            "Train Epoch: 74 [51200/60000 (85%)]\tLoss: 29.435003\n",
            "====> Epoch: 74 Average loss: 28.4354\n",
            "Train Epoch: 75 [0/60000 (0%)]\tLoss: 26.913343\n",
            "Train Epoch: 75 [12800/60000 (21%)]\tLoss: 28.773027\n",
            "Train Epoch: 75 [25600/60000 (43%)]\tLoss: 29.588287\n",
            "Train Epoch: 75 [38400/60000 (64%)]\tLoss: 29.284061\n",
            "Train Epoch: 75 [51200/60000 (85%)]\tLoss: 28.733936\n",
            "====> Epoch: 75 Average loss: 28.4299\n",
            "Train Epoch: 76 [0/60000 (0%)]\tLoss: 26.913218\n",
            "Train Epoch: 76 [12800/60000 (21%)]\tLoss: 27.661295\n",
            "Train Epoch: 76 [25600/60000 (43%)]\tLoss: 29.524101\n",
            "Train Epoch: 76 [38400/60000 (64%)]\tLoss: 28.507378\n",
            "Train Epoch: 76 [51200/60000 (85%)]\tLoss: 28.691603\n",
            "====> Epoch: 76 Average loss: 28.4087\n",
            "Train Epoch: 77 [0/60000 (0%)]\tLoss: 27.559164\n",
            "Train Epoch: 77 [12800/60000 (21%)]\tLoss: 27.795128\n",
            "Train Epoch: 77 [25600/60000 (43%)]\tLoss: 27.404129\n",
            "Train Epoch: 77 [38400/60000 (64%)]\tLoss: 28.358578\n",
            "Train Epoch: 77 [51200/60000 (85%)]\tLoss: 27.639135\n",
            "====> Epoch: 77 Average loss: 28.4209\n",
            "Train Epoch: 78 [0/60000 (0%)]\tLoss: 29.034966\n",
            "Train Epoch: 78 [12800/60000 (21%)]\tLoss: 29.811180\n",
            "Train Epoch: 78 [25600/60000 (43%)]\tLoss: 29.637085\n",
            "Train Epoch: 78 [38400/60000 (64%)]\tLoss: 27.645870\n",
            "Train Epoch: 78 [51200/60000 (85%)]\tLoss: 28.428677\n",
            "====> Epoch: 78 Average loss: 28.4126\n",
            "Train Epoch: 79 [0/60000 (0%)]\tLoss: 27.965721\n",
            "Train Epoch: 79 [12800/60000 (21%)]\tLoss: 27.198948\n",
            "Train Epoch: 79 [25600/60000 (43%)]\tLoss: 28.293667\n",
            "Train Epoch: 79 [38400/60000 (64%)]\tLoss: 28.237272\n",
            "Train Epoch: 79 [51200/60000 (85%)]\tLoss: 28.573784\n",
            "====> Epoch: 79 Average loss: 28.3829\n",
            "Train Epoch: 80 [0/60000 (0%)]\tLoss: 27.966743\n",
            "Train Epoch: 80 [12800/60000 (21%)]\tLoss: 27.565109\n",
            "Train Epoch: 80 [25600/60000 (43%)]\tLoss: 28.577538\n",
            "Train Epoch: 80 [38400/60000 (64%)]\tLoss: 29.774382\n",
            "Train Epoch: 80 [51200/60000 (85%)]\tLoss: 27.769997\n",
            "====> Epoch: 80 Average loss: 28.3584\n",
            "Train Epoch: 81 [0/60000 (0%)]\tLoss: 27.599871\n",
            "Train Epoch: 81 [12800/60000 (21%)]\tLoss: 29.416611\n",
            "Train Epoch: 81 [25600/60000 (43%)]\tLoss: 28.890789\n",
            "Train Epoch: 81 [38400/60000 (64%)]\tLoss: 27.619019\n",
            "Train Epoch: 81 [51200/60000 (85%)]\tLoss: 27.233898\n",
            "====> Epoch: 81 Average loss: 28.3566\n",
            "Train Epoch: 82 [0/60000 (0%)]\tLoss: 28.384815\n",
            "Train Epoch: 82 [12800/60000 (21%)]\tLoss: 28.125273\n",
            "Train Epoch: 82 [25600/60000 (43%)]\tLoss: 28.153301\n",
            "Train Epoch: 82 [38400/60000 (64%)]\tLoss: 28.103331\n",
            "Train Epoch: 82 [51200/60000 (85%)]\tLoss: 29.702631\n",
            "====> Epoch: 82 Average loss: 28.3608\n",
            "Train Epoch: 83 [0/60000 (0%)]\tLoss: 27.183475\n",
            "Train Epoch: 83 [12800/60000 (21%)]\tLoss: 29.344601\n",
            "Train Epoch: 83 [25600/60000 (43%)]\tLoss: 28.016485\n",
            "Train Epoch: 83 [38400/60000 (64%)]\tLoss: 28.293430\n",
            "Train Epoch: 83 [51200/60000 (85%)]\tLoss: 27.832127\n",
            "====> Epoch: 83 Average loss: 28.3689\n",
            "Train Epoch: 84 [0/60000 (0%)]\tLoss: 29.150988\n",
            "Train Epoch: 84 [12800/60000 (21%)]\tLoss: 28.002947\n",
            "Train Epoch: 84 [25600/60000 (43%)]\tLoss: 28.849167\n",
            "Train Epoch: 84 [38400/60000 (64%)]\tLoss: 28.223141\n",
            "Train Epoch: 84 [51200/60000 (85%)]\tLoss: 28.352545\n",
            "====> Epoch: 84 Average loss: 28.3467\n",
            "Train Epoch: 85 [0/60000 (0%)]\tLoss: 28.437208\n",
            "Train Epoch: 85 [12800/60000 (21%)]\tLoss: 27.775513\n",
            "Train Epoch: 85 [25600/60000 (43%)]\tLoss: 28.511555\n",
            "Train Epoch: 85 [38400/60000 (64%)]\tLoss: 28.893293\n",
            "Train Epoch: 85 [51200/60000 (85%)]\tLoss: 28.659126\n",
            "====> Epoch: 85 Average loss: 28.3502\n",
            "Train Epoch: 86 [0/60000 (0%)]\tLoss: 27.014542\n",
            "Train Epoch: 86 [12800/60000 (21%)]\tLoss: 29.123165\n",
            "Train Epoch: 86 [25600/60000 (43%)]\tLoss: 29.043320\n",
            "Train Epoch: 86 [38400/60000 (64%)]\tLoss: 28.117050\n",
            "Train Epoch: 86 [51200/60000 (85%)]\tLoss: 28.845741\n",
            "====> Epoch: 86 Average loss: 28.3174\n",
            "Train Epoch: 87 [0/60000 (0%)]\tLoss: 28.666916\n",
            "Train Epoch: 87 [12800/60000 (21%)]\tLoss: 28.112366\n",
            "Train Epoch: 87 [25600/60000 (43%)]\tLoss: 27.495909\n",
            "Train Epoch: 87 [38400/60000 (64%)]\tLoss: 28.407543\n",
            "Train Epoch: 87 [51200/60000 (85%)]\tLoss: 27.212788\n",
            "====> Epoch: 87 Average loss: 28.2921\n",
            "Train Epoch: 88 [0/60000 (0%)]\tLoss: 27.816761\n",
            "Train Epoch: 88 [12800/60000 (21%)]\tLoss: 28.666313\n",
            "Train Epoch: 88 [25600/60000 (43%)]\tLoss: 28.559486\n",
            "Train Epoch: 88 [38400/60000 (64%)]\tLoss: 29.464943\n",
            "Train Epoch: 88 [51200/60000 (85%)]\tLoss: 28.765463\n",
            "====> Epoch: 88 Average loss: 28.3135\n",
            "Train Epoch: 89 [0/60000 (0%)]\tLoss: 26.929474\n",
            "Train Epoch: 89 [12800/60000 (21%)]\tLoss: 27.855228\n",
            "Train Epoch: 89 [25600/60000 (43%)]\tLoss: 28.972145\n",
            "Train Epoch: 89 [38400/60000 (64%)]\tLoss: 26.738251\n",
            "Train Epoch: 89 [51200/60000 (85%)]\tLoss: 29.441246\n",
            "====> Epoch: 89 Average loss: 28.2954\n",
            "Train Epoch: 90 [0/60000 (0%)]\tLoss: 27.724209\n",
            "Train Epoch: 90 [12800/60000 (21%)]\tLoss: 27.789467\n",
            "Train Epoch: 90 [25600/60000 (43%)]\tLoss: 27.634676\n",
            "Train Epoch: 90 [38400/60000 (64%)]\tLoss: 27.696548\n",
            "Train Epoch: 90 [51200/60000 (85%)]\tLoss: 27.547249\n",
            "====> Epoch: 90 Average loss: 28.2783\n",
            "Train Epoch: 91 [0/60000 (0%)]\tLoss: 26.368877\n",
            "Train Epoch: 91 [12800/60000 (21%)]\tLoss: 28.663795\n",
            "Train Epoch: 91 [25600/60000 (43%)]\tLoss: 28.234627\n",
            "Train Epoch: 91 [38400/60000 (64%)]\tLoss: 28.434479\n",
            "Train Epoch: 91 [51200/60000 (85%)]\tLoss: 27.573151\n",
            "====> Epoch: 91 Average loss: 28.2880\n",
            "Train Epoch: 92 [0/60000 (0%)]\tLoss: 29.522337\n",
            "Train Epoch: 92 [12800/60000 (21%)]\tLoss: 28.801687\n",
            "Train Epoch: 92 [25600/60000 (43%)]\tLoss: 28.816357\n",
            "Train Epoch: 92 [38400/60000 (64%)]\tLoss: 28.211006\n",
            "Train Epoch: 92 [51200/60000 (85%)]\tLoss: 28.145126\n",
            "====> Epoch: 92 Average loss: 28.2752\n",
            "Train Epoch: 93 [0/60000 (0%)]\tLoss: 27.716545\n",
            "Train Epoch: 93 [12800/60000 (21%)]\tLoss: 30.383459\n",
            "Train Epoch: 93 [25600/60000 (43%)]\tLoss: 29.036753\n",
            "Train Epoch: 93 [38400/60000 (64%)]\tLoss: 28.933102\n",
            "Train Epoch: 93 [51200/60000 (85%)]\tLoss: 28.158743\n",
            "====> Epoch: 93 Average loss: 28.2640\n",
            "Train Epoch: 94 [0/60000 (0%)]\tLoss: 30.143238\n",
            "Train Epoch: 94 [12800/60000 (21%)]\tLoss: 28.082928\n",
            "Train Epoch: 94 [25600/60000 (43%)]\tLoss: 29.363441\n",
            "Train Epoch: 94 [38400/60000 (64%)]\tLoss: 28.926088\n",
            "Train Epoch: 94 [51200/60000 (85%)]\tLoss: 28.181503\n",
            "====> Epoch: 94 Average loss: 28.2567\n",
            "Train Epoch: 95 [0/60000 (0%)]\tLoss: 28.517136\n",
            "Train Epoch: 95 [12800/60000 (21%)]\tLoss: 28.665684\n",
            "Train Epoch: 95 [25600/60000 (43%)]\tLoss: 29.557377\n",
            "Train Epoch: 95 [38400/60000 (64%)]\tLoss: 28.231874\n",
            "Train Epoch: 95 [51200/60000 (85%)]\tLoss: 28.565004\n",
            "====> Epoch: 95 Average loss: 28.2676\n",
            "Train Epoch: 96 [0/60000 (0%)]\tLoss: 28.333080\n",
            "Train Epoch: 96 [12800/60000 (21%)]\tLoss: 29.080826\n",
            "Train Epoch: 96 [25600/60000 (43%)]\tLoss: 28.604374\n",
            "Train Epoch: 96 [38400/60000 (64%)]\tLoss: 27.821625\n",
            "Train Epoch: 96 [51200/60000 (85%)]\tLoss: 28.596039\n",
            "====> Epoch: 96 Average loss: 28.2280\n",
            "Train Epoch: 97 [0/60000 (0%)]\tLoss: 28.837265\n",
            "Train Epoch: 97 [12800/60000 (21%)]\tLoss: 25.931965\n",
            "Train Epoch: 97 [25600/60000 (43%)]\tLoss: 28.122627\n",
            "Train Epoch: 97 [38400/60000 (64%)]\tLoss: 27.646299\n",
            "Train Epoch: 97 [51200/60000 (85%)]\tLoss: 29.303064\n",
            "====> Epoch: 97 Average loss: 28.2301\n",
            "Train Epoch: 98 [0/60000 (0%)]\tLoss: 29.011553\n",
            "Train Epoch: 98 [12800/60000 (21%)]\tLoss: 28.155640\n",
            "Train Epoch: 98 [25600/60000 (43%)]\tLoss: 27.261230\n",
            "Train Epoch: 98 [38400/60000 (64%)]\tLoss: 28.759323\n",
            "Train Epoch: 98 [51200/60000 (85%)]\tLoss: 28.134258\n",
            "====> Epoch: 98 Average loss: 28.2378\n",
            "Train Epoch: 99 [0/60000 (0%)]\tLoss: 28.482683\n",
            "Train Epoch: 99 [12800/60000 (21%)]\tLoss: 28.821735\n",
            "Train Epoch: 99 [25600/60000 (43%)]\tLoss: 28.572102\n",
            "Train Epoch: 99 [38400/60000 (64%)]\tLoss: 28.182608\n",
            "Train Epoch: 99 [51200/60000 (85%)]\tLoss: 27.910851\n",
            "====> Epoch: 99 Average loss: 28.2431\n",
            "Train Epoch: 100 [0/60000 (0%)]\tLoss: 28.274223\n",
            "Train Epoch: 100 [12800/60000 (21%)]\tLoss: 28.412317\n",
            "Train Epoch: 100 [25600/60000 (43%)]\tLoss: 27.760702\n",
            "Train Epoch: 100 [38400/60000 (64%)]\tLoss: 27.606453\n",
            "Train Epoch: 100 [51200/60000 (85%)]\tLoss: 28.919605\n",
            "====> Epoch: 100 Average loss: 28.2104\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "T0At9m43U1pj",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "88dfba42-6b91-4dc0-93de-a7d28f29fc01"
      },
      "source": [
        "for epoch in range(num_epochs):\n",
        "    predModel.train()\n",
        "    train_loss = 0\n",
        "    for batch_idx, data in enumerate(dataloader):\n",
        "        img, _ = data\n",
        "        img = img.view(img.size(0), -1)\n",
        "        img = Variable(img)\n",
        "        if torch.cuda.is_available():\n",
        "            img = img.cuda()\n",
        "        optimizer.zero_grad()\n",
        "        mu, logvar = model.encode(img)\n",
        "        modelOutput = model.reparametrize(mu, logvar)\n",
        "        \n",
        "        predOutput = predModel(img)\n",
        "        recon_batch = model.decode(predOutput)\n",
        "        predLoss = pred_loss_function(predOutput, modelOutput)\n",
        "        predLoss.backward()\n",
        "        train_loss += predLoss.item()\n",
        "        optimizer.step()\n",
        "        if batch_idx % 100 == 0:\n",
        "            print('Train Epoch: {} [{}/{} ({:.0f}%)]\\tLoss: {:.6f}'.format(\n",
        "                epoch,\n",
        "                batch_idx * len(img),\n",
        "                len(dataloader.dataset), 100. * batch_idx / len(dataloader),\n",
        "                predLoss.item() / len(img)))\n",
        "\n",
        "    print('====> Epoch: {} Average loss: {:.4f}'.format(\n",
        "        epoch, train_loss / len(dataloader.dataset)))\n",
        "    if epoch % 10 == 0:\n",
        "        save = to_img(recon_batch.cpu().data)\n",
        "        save_image(save, './vae_img_pred/image_{}.png'.format(epoch))\n",
        "\n",
        "torch.save(predModel.state_dict(), './vaePred.pth')"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Train Epoch: 0 [0/60000 (0%)]\tLoss: 39.993687\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/torch/nn/functional.py:1351: UserWarning: nn.functional.sigmoid is deprecated. Use torch.sigmoid instead.\n",
            "  warnings.warn(\"nn.functional.sigmoid is deprecated. Use torch.sigmoid instead.\")\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Train Epoch: 0 [12800/60000 (21%)]\tLoss: 19.636124\n",
            "Train Epoch: 0 [25600/60000 (43%)]\tLoss: 21.055206\n",
            "Train Epoch: 0 [38400/60000 (64%)]\tLoss: 20.819111\n",
            "Train Epoch: 0 [51200/60000 (85%)]\tLoss: 19.913528\n",
            "====> Epoch: 0 Average loss: 20.7957\n",
            "Train Epoch: 1 [0/60000 (0%)]\tLoss: 19.209724\n",
            "Train Epoch: 1 [12800/60000 (21%)]\tLoss: 20.452333\n",
            "Train Epoch: 1 [25600/60000 (43%)]\tLoss: 20.270781\n",
            "Train Epoch: 1 [38400/60000 (64%)]\tLoss: 20.551083\n",
            "Train Epoch: 1 [51200/60000 (85%)]\tLoss: 19.661083\n",
            "====> Epoch: 1 Average loss: 20.0668\n",
            "Train Epoch: 2 [0/60000 (0%)]\tLoss: 19.698915\n",
            "Train Epoch: 2 [12800/60000 (21%)]\tLoss: 19.667227\n",
            "Train Epoch: 2 [25600/60000 (43%)]\tLoss: 20.088314\n",
            "Train Epoch: 2 [38400/60000 (64%)]\tLoss: 20.461121\n",
            "Train Epoch: 2 [51200/60000 (85%)]\tLoss: 20.232166\n",
            "====> Epoch: 2 Average loss: 20.0199\n",
            "Train Epoch: 3 [0/60000 (0%)]\tLoss: 20.044392\n",
            "Train Epoch: 3 [12800/60000 (21%)]\tLoss: 20.265114\n",
            "Train Epoch: 3 [25600/60000 (43%)]\tLoss: 19.650852\n",
            "Train Epoch: 3 [38400/60000 (64%)]\tLoss: 19.051481\n",
            "Train Epoch: 3 [51200/60000 (85%)]\tLoss: 20.084278\n",
            "====> Epoch: 3 Average loss: 20.0438\n",
            "Train Epoch: 4 [0/60000 (0%)]\tLoss: 19.616871\n",
            "Train Epoch: 4 [12800/60000 (21%)]\tLoss: 19.611410\n",
            "Train Epoch: 4 [25600/60000 (43%)]\tLoss: 19.652416\n",
            "Train Epoch: 4 [38400/60000 (64%)]\tLoss: 20.019838\n",
            "Train Epoch: 4 [51200/60000 (85%)]\tLoss: 21.771347\n",
            "====> Epoch: 4 Average loss: 20.0538\n",
            "Train Epoch: 5 [0/60000 (0%)]\tLoss: 18.683432\n",
            "Train Epoch: 5 [12800/60000 (21%)]\tLoss: 19.445415\n",
            "Train Epoch: 5 [25600/60000 (43%)]\tLoss: 19.691994\n",
            "Train Epoch: 5 [38400/60000 (64%)]\tLoss: 20.463570\n",
            "Train Epoch: 5 [51200/60000 (85%)]\tLoss: 20.566708\n",
            "====> Epoch: 5 Average loss: 20.0130\n",
            "Train Epoch: 6 [0/60000 (0%)]\tLoss: 18.528378\n",
            "Train Epoch: 6 [12800/60000 (21%)]\tLoss: 19.669283\n",
            "Train Epoch: 6 [25600/60000 (43%)]\tLoss: 20.459352\n",
            "Train Epoch: 6 [38400/60000 (64%)]\tLoss: 19.831778\n",
            "Train Epoch: 6 [51200/60000 (85%)]\tLoss: 20.631065\n",
            "====> Epoch: 6 Average loss: 20.0061\n",
            "Train Epoch: 7 [0/60000 (0%)]\tLoss: 19.555248\n",
            "Train Epoch: 7 [12800/60000 (21%)]\tLoss: 19.145412\n",
            "Train Epoch: 7 [25600/60000 (43%)]\tLoss: 19.538710\n",
            "Train Epoch: 7 [38400/60000 (64%)]\tLoss: 20.564850\n",
            "Train Epoch: 7 [51200/60000 (85%)]\tLoss: 20.816174\n",
            "====> Epoch: 7 Average loss: 20.0174\n",
            "Train Epoch: 8 [0/60000 (0%)]\tLoss: 20.223034\n",
            "Train Epoch: 8 [12800/60000 (21%)]\tLoss: 19.662338\n",
            "Train Epoch: 8 [25600/60000 (43%)]\tLoss: 20.337530\n",
            "Train Epoch: 8 [38400/60000 (64%)]\tLoss: 19.753517\n",
            "Train Epoch: 8 [51200/60000 (85%)]\tLoss: 19.937868\n",
            "====> Epoch: 8 Average loss: 19.9994\n",
            "Train Epoch: 9 [0/60000 (0%)]\tLoss: 20.285370\n",
            "Train Epoch: 9 [12800/60000 (21%)]\tLoss: 20.026413\n",
            "Train Epoch: 9 [25600/60000 (43%)]\tLoss: 19.922441\n",
            "Train Epoch: 9 [38400/60000 (64%)]\tLoss: 20.199371\n",
            "Train Epoch: 9 [51200/60000 (85%)]\tLoss: 20.398024\n",
            "====> Epoch: 9 Average loss: 20.0585\n",
            "Train Epoch: 10 [0/60000 (0%)]\tLoss: 19.668026\n",
            "Train Epoch: 10 [12800/60000 (21%)]\tLoss: 20.793535\n",
            "Train Epoch: 10 [25600/60000 (43%)]\tLoss: 20.504663\n",
            "Train Epoch: 10 [38400/60000 (64%)]\tLoss: 20.868729\n",
            "Train Epoch: 10 [51200/60000 (85%)]\tLoss: 19.386232\n",
            "====> Epoch: 10 Average loss: 20.0241\n",
            "Train Epoch: 11 [0/60000 (0%)]\tLoss: 19.582266\n",
            "Train Epoch: 11 [12800/60000 (21%)]\tLoss: 19.684624\n",
            "Train Epoch: 11 [25600/60000 (43%)]\tLoss: 19.679691\n",
            "Train Epoch: 11 [38400/60000 (64%)]\tLoss: 19.523968\n",
            "Train Epoch: 11 [51200/60000 (85%)]\tLoss: 20.255585\n",
            "====> Epoch: 11 Average loss: 20.0375\n",
            "Train Epoch: 12 [0/60000 (0%)]\tLoss: 19.879822\n",
            "Train Epoch: 12 [12800/60000 (21%)]\tLoss: 19.825710\n",
            "Train Epoch: 12 [25600/60000 (43%)]\tLoss: 18.041891\n",
            "Train Epoch: 12 [38400/60000 (64%)]\tLoss: 21.116703\n",
            "Train Epoch: 12 [51200/60000 (85%)]\tLoss: 19.925516\n",
            "====> Epoch: 12 Average loss: 20.0323\n",
            "Train Epoch: 13 [0/60000 (0%)]\tLoss: 20.550936\n",
            "Train Epoch: 13 [12800/60000 (21%)]\tLoss: 20.125298\n",
            "Train Epoch: 13 [25600/60000 (43%)]\tLoss: 19.711094\n",
            "Train Epoch: 13 [38400/60000 (64%)]\tLoss: 20.447325\n",
            "Train Epoch: 13 [51200/60000 (85%)]\tLoss: 20.066383\n",
            "====> Epoch: 13 Average loss: 20.0201\n",
            "Train Epoch: 14 [0/60000 (0%)]\tLoss: 18.447266\n",
            "Train Epoch: 14 [12800/60000 (21%)]\tLoss: 19.271639\n",
            "Train Epoch: 14 [25600/60000 (43%)]\tLoss: 20.120819\n",
            "Train Epoch: 14 [38400/60000 (64%)]\tLoss: 21.318417\n",
            "Train Epoch: 14 [51200/60000 (85%)]\tLoss: 20.111935\n",
            "====> Epoch: 14 Average loss: 19.9526\n",
            "Train Epoch: 15 [0/60000 (0%)]\tLoss: 19.830589\n",
            "Train Epoch: 15 [12800/60000 (21%)]\tLoss: 19.255384\n",
            "Train Epoch: 15 [25600/60000 (43%)]\tLoss: 21.335098\n",
            "Train Epoch: 15 [38400/60000 (64%)]\tLoss: 20.305670\n",
            "Train Epoch: 15 [51200/60000 (85%)]\tLoss: 19.864239\n",
            "====> Epoch: 15 Average loss: 19.9698\n",
            "Train Epoch: 16 [0/60000 (0%)]\tLoss: 20.061644\n",
            "Train Epoch: 16 [12800/60000 (21%)]\tLoss: 21.108727\n",
            "Train Epoch: 16 [25600/60000 (43%)]\tLoss: 20.062408\n",
            "Train Epoch: 16 [38400/60000 (64%)]\tLoss: 20.943743\n",
            "Train Epoch: 16 [51200/60000 (85%)]\tLoss: 19.438313\n",
            "====> Epoch: 16 Average loss: 20.0147\n",
            "Train Epoch: 17 [0/60000 (0%)]\tLoss: 21.165827\n",
            "Train Epoch: 17 [12800/60000 (21%)]\tLoss: 19.270548\n",
            "Train Epoch: 17 [25600/60000 (43%)]\tLoss: 21.153645\n",
            "Train Epoch: 17 [38400/60000 (64%)]\tLoss: 19.756405\n",
            "Train Epoch: 17 [51200/60000 (85%)]\tLoss: 21.287052\n",
            "====> Epoch: 17 Average loss: 19.9990\n",
            "Train Epoch: 18 [0/60000 (0%)]\tLoss: 20.433723\n",
            "Train Epoch: 18 [12800/60000 (21%)]\tLoss: 20.001890\n",
            "Train Epoch: 18 [25600/60000 (43%)]\tLoss: 20.633751\n",
            "Train Epoch: 18 [38400/60000 (64%)]\tLoss: 20.209759\n",
            "Train Epoch: 18 [51200/60000 (85%)]\tLoss: 19.513275\n",
            "====> Epoch: 18 Average loss: 19.9803\n",
            "Train Epoch: 19 [0/60000 (0%)]\tLoss: 19.855011\n",
            "Train Epoch: 19 [12800/60000 (21%)]\tLoss: 20.007402\n",
            "Train Epoch: 19 [25600/60000 (43%)]\tLoss: 20.730444\n",
            "Train Epoch: 19 [38400/60000 (64%)]\tLoss: 19.752390\n",
            "Train Epoch: 19 [51200/60000 (85%)]\tLoss: 19.999321\n",
            "====> Epoch: 19 Average loss: 19.9532\n",
            "Train Epoch: 20 [0/60000 (0%)]\tLoss: 20.418552\n",
            "Train Epoch: 20 [12800/60000 (21%)]\tLoss: 19.096544\n",
            "Train Epoch: 20 [25600/60000 (43%)]\tLoss: 20.105227\n",
            "Train Epoch: 20 [38400/60000 (64%)]\tLoss: 19.885435\n",
            "Train Epoch: 20 [51200/60000 (85%)]\tLoss: 18.284855\n",
            "====> Epoch: 20 Average loss: 19.9957\n",
            "Train Epoch: 21 [0/60000 (0%)]\tLoss: 19.362625\n",
            "Train Epoch: 21 [12800/60000 (21%)]\tLoss: 20.199848\n",
            "Train Epoch: 21 [25600/60000 (43%)]\tLoss: 19.973104\n",
            "Train Epoch: 21 [38400/60000 (64%)]\tLoss: 19.925529\n",
            "Train Epoch: 21 [51200/60000 (85%)]\tLoss: 19.712021\n",
            "====> Epoch: 21 Average loss: 19.9710\n",
            "Train Epoch: 22 [0/60000 (0%)]\tLoss: 19.755013\n",
            "Train Epoch: 22 [12800/60000 (21%)]\tLoss: 19.599773\n",
            "Train Epoch: 22 [25600/60000 (43%)]\tLoss: 19.786974\n",
            "Train Epoch: 22 [38400/60000 (64%)]\tLoss: 19.993164\n",
            "Train Epoch: 22 [51200/60000 (85%)]\tLoss: 19.731730\n",
            "====> Epoch: 22 Average loss: 19.9414\n",
            "Train Epoch: 23 [0/60000 (0%)]\tLoss: 20.341755\n",
            "Train Epoch: 23 [12800/60000 (21%)]\tLoss: 20.268456\n",
            "Train Epoch: 23 [25600/60000 (43%)]\tLoss: 20.344053\n",
            "Train Epoch: 23 [38400/60000 (64%)]\tLoss: 21.070671\n",
            "Train Epoch: 23 [51200/60000 (85%)]\tLoss: 19.836121\n",
            "====> Epoch: 23 Average loss: 19.9920\n",
            "Train Epoch: 24 [0/60000 (0%)]\tLoss: 19.702948\n",
            "Train Epoch: 24 [12800/60000 (21%)]\tLoss: 20.391441\n",
            "Train Epoch: 24 [25600/60000 (43%)]\tLoss: 19.676199\n",
            "Train Epoch: 24 [38400/60000 (64%)]\tLoss: 19.493748\n",
            "Train Epoch: 24 [51200/60000 (85%)]\tLoss: 20.034649\n",
            "====> Epoch: 24 Average loss: 19.9425\n",
            "Train Epoch: 25 [0/60000 (0%)]\tLoss: 19.390312\n",
            "Train Epoch: 25 [12800/60000 (21%)]\tLoss: 19.026569\n",
            "Train Epoch: 25 [25600/60000 (43%)]\tLoss: 20.897068\n",
            "Train Epoch: 25 [38400/60000 (64%)]\tLoss: 20.388866\n",
            "Train Epoch: 25 [51200/60000 (85%)]\tLoss: 20.018572\n",
            "====> Epoch: 25 Average loss: 19.9673\n",
            "Train Epoch: 26 [0/60000 (0%)]\tLoss: 20.280178\n",
            "Train Epoch: 26 [12800/60000 (21%)]\tLoss: 20.181488\n",
            "Train Epoch: 26 [25600/60000 (43%)]\tLoss: 20.262659\n",
            "Train Epoch: 26 [38400/60000 (64%)]\tLoss: 20.385120\n",
            "Train Epoch: 26 [51200/60000 (85%)]\tLoss: 20.405592\n",
            "====> Epoch: 26 Average loss: 19.9330\n",
            "Train Epoch: 27 [0/60000 (0%)]\tLoss: 19.790707\n",
            "Train Epoch: 27 [12800/60000 (21%)]\tLoss: 19.976913\n",
            "Train Epoch: 27 [25600/60000 (43%)]\tLoss: 20.505503\n",
            "Train Epoch: 27 [38400/60000 (64%)]\tLoss: 19.210121\n",
            "Train Epoch: 27 [51200/60000 (85%)]\tLoss: 20.809752\n",
            "====> Epoch: 27 Average loss: 19.9866\n",
            "Train Epoch: 28 [0/60000 (0%)]\tLoss: 19.576040\n",
            "Train Epoch: 28 [12800/60000 (21%)]\tLoss: 20.599865\n",
            "Train Epoch: 28 [25600/60000 (43%)]\tLoss: 20.747488\n",
            "Train Epoch: 28 [38400/60000 (64%)]\tLoss: 20.607998\n",
            "Train Epoch: 28 [51200/60000 (85%)]\tLoss: 19.782717\n",
            "====> Epoch: 28 Average loss: 20.0024\n",
            "Train Epoch: 29 [0/60000 (0%)]\tLoss: 20.710848\n",
            "Train Epoch: 29 [12800/60000 (21%)]\tLoss: 19.754555\n",
            "Train Epoch: 29 [25600/60000 (43%)]\tLoss: 20.629543\n",
            "Train Epoch: 29 [38400/60000 (64%)]\tLoss: 20.188084\n",
            "Train Epoch: 29 [51200/60000 (85%)]\tLoss: 19.495066\n",
            "====> Epoch: 29 Average loss: 19.9907\n",
            "Train Epoch: 30 [0/60000 (0%)]\tLoss: 20.422445\n",
            "Train Epoch: 30 [12800/60000 (21%)]\tLoss: 20.751282\n",
            "Train Epoch: 30 [25600/60000 (43%)]\tLoss: 19.681044\n",
            "Train Epoch: 30 [38400/60000 (64%)]\tLoss: 20.117010\n",
            "Train Epoch: 30 [51200/60000 (85%)]\tLoss: 19.649240\n",
            "====> Epoch: 30 Average loss: 20.0262\n",
            "Train Epoch: 31 [0/60000 (0%)]\tLoss: 20.100983\n",
            "Train Epoch: 31 [12800/60000 (21%)]\tLoss: 20.134201\n",
            "Train Epoch: 31 [25600/60000 (43%)]\tLoss: 20.713932\n",
            "Train Epoch: 31 [38400/60000 (64%)]\tLoss: 20.266935\n",
            "Train Epoch: 31 [51200/60000 (85%)]\tLoss: 20.481707\n",
            "====> Epoch: 31 Average loss: 19.9887\n",
            "Train Epoch: 32 [0/60000 (0%)]\tLoss: 18.955809\n",
            "Train Epoch: 32 [12800/60000 (21%)]\tLoss: 19.723379\n",
            "Train Epoch: 32 [25600/60000 (43%)]\tLoss: 21.518751\n",
            "Train Epoch: 32 [38400/60000 (64%)]\tLoss: 19.195950\n",
            "Train Epoch: 32 [51200/60000 (85%)]\tLoss: 19.091940\n",
            "====> Epoch: 32 Average loss: 19.9951\n",
            "Train Epoch: 33 [0/60000 (0%)]\tLoss: 19.927126\n",
            "Train Epoch: 33 [12800/60000 (21%)]\tLoss: 19.078527\n",
            "Train Epoch: 33 [25600/60000 (43%)]\tLoss: 19.943741\n",
            "Train Epoch: 33 [38400/60000 (64%)]\tLoss: 19.578518\n",
            "Train Epoch: 33 [51200/60000 (85%)]\tLoss: 20.201696\n",
            "====> Epoch: 33 Average loss: 19.9738\n",
            "Train Epoch: 34 [0/60000 (0%)]\tLoss: 18.825113\n",
            "Train Epoch: 34 [12800/60000 (21%)]\tLoss: 19.630396\n",
            "Train Epoch: 34 [25600/60000 (43%)]\tLoss: 20.541348\n",
            "Train Epoch: 34 [38400/60000 (64%)]\tLoss: 19.325077\n",
            "Train Epoch: 34 [51200/60000 (85%)]\tLoss: 19.796093\n",
            "====> Epoch: 34 Average loss: 19.9973\n",
            "Train Epoch: 35 [0/60000 (0%)]\tLoss: 20.356937\n",
            "Train Epoch: 35 [12800/60000 (21%)]\tLoss: 19.788980\n",
            "Train Epoch: 35 [25600/60000 (43%)]\tLoss: 19.528618\n",
            "Train Epoch: 35 [38400/60000 (64%)]\tLoss: 20.295414\n",
            "Train Epoch: 35 [51200/60000 (85%)]\tLoss: 20.950293\n",
            "====> Epoch: 35 Average loss: 20.0255\n",
            "Train Epoch: 36 [0/60000 (0%)]\tLoss: 19.779049\n",
            "Train Epoch: 36 [12800/60000 (21%)]\tLoss: 20.754974\n",
            "Train Epoch: 36 [25600/60000 (43%)]\tLoss: 20.320572\n",
            "Train Epoch: 36 [38400/60000 (64%)]\tLoss: 20.693607\n",
            "Train Epoch: 36 [51200/60000 (85%)]\tLoss: 19.746826\n",
            "====> Epoch: 36 Average loss: 19.9869\n",
            "Train Epoch: 37 [0/60000 (0%)]\tLoss: 20.258955\n",
            "Train Epoch: 37 [12800/60000 (21%)]\tLoss: 20.024189\n",
            "Train Epoch: 37 [25600/60000 (43%)]\tLoss: 21.512693\n",
            "Train Epoch: 37 [38400/60000 (64%)]\tLoss: 19.348824\n",
            "Train Epoch: 37 [51200/60000 (85%)]\tLoss: 19.874678\n",
            "====> Epoch: 37 Average loss: 19.9932\n",
            "Train Epoch: 38 [0/60000 (0%)]\tLoss: 20.183319\n",
            "Train Epoch: 38 [12800/60000 (21%)]\tLoss: 19.706316\n",
            "Train Epoch: 38 [25600/60000 (43%)]\tLoss: 20.585436\n",
            "Train Epoch: 38 [38400/60000 (64%)]\tLoss: 19.859148\n",
            "Train Epoch: 38 [51200/60000 (85%)]\tLoss: 19.765354\n",
            "====> Epoch: 38 Average loss: 19.9094\n",
            "Train Epoch: 39 [0/60000 (0%)]\tLoss: 19.774048\n",
            "Train Epoch: 39 [12800/60000 (21%)]\tLoss: 20.347124\n",
            "Train Epoch: 39 [25600/60000 (43%)]\tLoss: 18.607929\n",
            "Train Epoch: 39 [38400/60000 (64%)]\tLoss: 20.425106\n",
            "Train Epoch: 39 [51200/60000 (85%)]\tLoss: 19.691223\n",
            "====> Epoch: 39 Average loss: 19.9671\n",
            "Train Epoch: 40 [0/60000 (0%)]\tLoss: 20.090586\n",
            "Train Epoch: 40 [12800/60000 (21%)]\tLoss: 20.635227\n",
            "Train Epoch: 40 [25600/60000 (43%)]\tLoss: 19.962898\n",
            "Train Epoch: 40 [38400/60000 (64%)]\tLoss: 20.508762\n",
            "Train Epoch: 40 [51200/60000 (85%)]\tLoss: 19.755997\n",
            "====> Epoch: 40 Average loss: 20.0215\n",
            "Train Epoch: 41 [0/60000 (0%)]\tLoss: 20.024172\n",
            "Train Epoch: 41 [12800/60000 (21%)]\tLoss: 19.394394\n",
            "Train Epoch: 41 [25600/60000 (43%)]\tLoss: 19.783966\n",
            "Train Epoch: 41 [38400/60000 (64%)]\tLoss: 20.761038\n",
            "Train Epoch: 41 [51200/60000 (85%)]\tLoss: 20.209162\n",
            "====> Epoch: 41 Average loss: 19.9918\n",
            "Train Epoch: 42 [0/60000 (0%)]\tLoss: 21.346157\n",
            "Train Epoch: 42 [12800/60000 (21%)]\tLoss: 20.019094\n",
            "Train Epoch: 42 [25600/60000 (43%)]\tLoss: 20.559587\n",
            "Train Epoch: 42 [38400/60000 (64%)]\tLoss: 20.967331\n",
            "Train Epoch: 42 [51200/60000 (85%)]\tLoss: 19.676228\n",
            "====> Epoch: 42 Average loss: 19.9888\n",
            "Train Epoch: 43 [0/60000 (0%)]\tLoss: 19.094753\n",
            "Train Epoch: 43 [12800/60000 (21%)]\tLoss: 20.710886\n",
            "Train Epoch: 43 [25600/60000 (43%)]\tLoss: 19.477913\n",
            "Train Epoch: 43 [38400/60000 (64%)]\tLoss: 20.566317\n",
            "Train Epoch: 43 [51200/60000 (85%)]\tLoss: 19.593184\n",
            "====> Epoch: 43 Average loss: 20.0079\n",
            "Train Epoch: 44 [0/60000 (0%)]\tLoss: 19.983887\n",
            "Train Epoch: 44 [12800/60000 (21%)]\tLoss: 19.791988\n",
            "Train Epoch: 44 [25600/60000 (43%)]\tLoss: 20.663624\n",
            "Train Epoch: 44 [38400/60000 (64%)]\tLoss: 19.812506\n",
            "Train Epoch: 44 [51200/60000 (85%)]\tLoss: 19.962227\n",
            "====> Epoch: 44 Average loss: 19.9550\n",
            "Train Epoch: 45 [0/60000 (0%)]\tLoss: 20.673115\n",
            "Train Epoch: 45 [12800/60000 (21%)]\tLoss: 19.512684\n",
            "Train Epoch: 45 [25600/60000 (43%)]\tLoss: 20.243206\n",
            "Train Epoch: 45 [38400/60000 (64%)]\tLoss: 19.127768\n",
            "Train Epoch: 45 [51200/60000 (85%)]\tLoss: 19.758715\n",
            "====> Epoch: 45 Average loss: 19.9477\n",
            "Train Epoch: 46 [0/60000 (0%)]\tLoss: 20.064548\n",
            "Train Epoch: 46 [12800/60000 (21%)]\tLoss: 19.399679\n",
            "Train Epoch: 46 [25600/60000 (43%)]\tLoss: 19.874901\n",
            "Train Epoch: 46 [38400/60000 (64%)]\tLoss: 20.441690\n",
            "Train Epoch: 46 [51200/60000 (85%)]\tLoss: 19.634974\n",
            "====> Epoch: 46 Average loss: 20.0149\n",
            "Train Epoch: 47 [0/60000 (0%)]\tLoss: 20.463827\n",
            "Train Epoch: 47 [12800/60000 (21%)]\tLoss: 21.111916\n",
            "Train Epoch: 47 [25600/60000 (43%)]\tLoss: 19.739948\n",
            "Train Epoch: 47 [38400/60000 (64%)]\tLoss: 19.361023\n",
            "Train Epoch: 47 [51200/60000 (85%)]\tLoss: 19.429485\n",
            "====> Epoch: 47 Average loss: 19.9767\n",
            "Train Epoch: 48 [0/60000 (0%)]\tLoss: 20.791615\n",
            "Train Epoch: 48 [12800/60000 (21%)]\tLoss: 20.349117\n",
            "Train Epoch: 48 [25600/60000 (43%)]\tLoss: 19.427502\n",
            "Train Epoch: 48 [38400/60000 (64%)]\tLoss: 20.869255\n",
            "Train Epoch: 48 [51200/60000 (85%)]\tLoss: 19.049589\n",
            "====> Epoch: 48 Average loss: 20.0008\n",
            "Train Epoch: 49 [0/60000 (0%)]\tLoss: 20.126305\n",
            "Train Epoch: 49 [12800/60000 (21%)]\tLoss: 21.338360\n",
            "Train Epoch: 49 [25600/60000 (43%)]\tLoss: 19.199888\n",
            "Train Epoch: 49 [38400/60000 (64%)]\tLoss: 20.414064\n",
            "Train Epoch: 49 [51200/60000 (85%)]\tLoss: 19.713963\n",
            "====> Epoch: 49 Average loss: 19.9800\n",
            "Train Epoch: 50 [0/60000 (0%)]\tLoss: 20.138851\n",
            "Train Epoch: 50 [12800/60000 (21%)]\tLoss: 21.339949\n",
            "Train Epoch: 50 [25600/60000 (43%)]\tLoss: 20.372168\n",
            "Train Epoch: 50 [38400/60000 (64%)]\tLoss: 19.485054\n",
            "Train Epoch: 50 [51200/60000 (85%)]\tLoss: 19.655746\n",
            "====> Epoch: 50 Average loss: 19.9934\n",
            "Train Epoch: 51 [0/60000 (0%)]\tLoss: 20.573212\n",
            "Train Epoch: 51 [12800/60000 (21%)]\tLoss: 20.691793\n",
            "Train Epoch: 51 [25600/60000 (43%)]\tLoss: 19.384775\n",
            "Train Epoch: 51 [38400/60000 (64%)]\tLoss: 20.034410\n",
            "Train Epoch: 51 [51200/60000 (85%)]\tLoss: 18.925842\n",
            "====> Epoch: 51 Average loss: 20.0107\n",
            "Train Epoch: 52 [0/60000 (0%)]\tLoss: 20.825178\n",
            "Train Epoch: 52 [12800/60000 (21%)]\tLoss: 20.694904\n",
            "Train Epoch: 52 [25600/60000 (43%)]\tLoss: 19.715313\n",
            "Train Epoch: 52 [38400/60000 (64%)]\tLoss: 19.563185\n",
            "Train Epoch: 52 [51200/60000 (85%)]\tLoss: 20.767424\n",
            "====> Epoch: 52 Average loss: 19.9727\n",
            "Train Epoch: 53 [0/60000 (0%)]\tLoss: 19.513432\n",
            "Train Epoch: 53 [12800/60000 (21%)]\tLoss: 19.845673\n",
            "Train Epoch: 53 [25600/60000 (43%)]\tLoss: 20.161777\n",
            "Train Epoch: 53 [38400/60000 (64%)]\tLoss: 20.015633\n",
            "Train Epoch: 53 [51200/60000 (85%)]\tLoss: 20.685760\n",
            "====> Epoch: 53 Average loss: 19.9532\n",
            "Train Epoch: 54 [0/60000 (0%)]\tLoss: 19.854195\n",
            "Train Epoch: 54 [12800/60000 (21%)]\tLoss: 19.563255\n",
            "Train Epoch: 54 [25600/60000 (43%)]\tLoss: 20.917788\n",
            "Train Epoch: 54 [38400/60000 (64%)]\tLoss: 18.969898\n",
            "Train Epoch: 54 [51200/60000 (85%)]\tLoss: 20.054880\n",
            "====> Epoch: 54 Average loss: 19.9948\n",
            "Train Epoch: 55 [0/60000 (0%)]\tLoss: 19.534626\n",
            "Train Epoch: 55 [12800/60000 (21%)]\tLoss: 19.553757\n",
            "Train Epoch: 55 [25600/60000 (43%)]\tLoss: 20.593679\n",
            "Train Epoch: 55 [38400/60000 (64%)]\tLoss: 20.031868\n",
            "Train Epoch: 55 [51200/60000 (85%)]\tLoss: 19.661896\n",
            "====> Epoch: 55 Average loss: 19.9478\n",
            "Train Epoch: 56 [0/60000 (0%)]\tLoss: 20.152821\n",
            "Train Epoch: 56 [12800/60000 (21%)]\tLoss: 21.173244\n",
            "Train Epoch: 56 [25600/60000 (43%)]\tLoss: 19.703426\n",
            "Train Epoch: 56 [38400/60000 (64%)]\tLoss: 18.988256\n",
            "Train Epoch: 56 [51200/60000 (85%)]\tLoss: 20.363018\n",
            "====> Epoch: 56 Average loss: 20.0102\n",
            "Train Epoch: 57 [0/60000 (0%)]\tLoss: 20.014944\n",
            "Train Epoch: 57 [12800/60000 (21%)]\tLoss: 20.626743\n",
            "Train Epoch: 57 [25600/60000 (43%)]\tLoss: 20.640427\n",
            "Train Epoch: 57 [38400/60000 (64%)]\tLoss: 20.131794\n",
            "Train Epoch: 57 [51200/60000 (85%)]\tLoss: 20.480860\n",
            "====> Epoch: 57 Average loss: 19.9956\n",
            "Train Epoch: 58 [0/60000 (0%)]\tLoss: 19.950157\n",
            "Train Epoch: 58 [12800/60000 (21%)]\tLoss: 20.468365\n",
            "Train Epoch: 58 [25600/60000 (43%)]\tLoss: 20.612360\n",
            "Train Epoch: 58 [38400/60000 (64%)]\tLoss: 20.384529\n",
            "Train Epoch: 58 [51200/60000 (85%)]\tLoss: 20.139072\n",
            "====> Epoch: 58 Average loss: 20.0059\n",
            "Train Epoch: 59 [0/60000 (0%)]\tLoss: 19.748848\n",
            "Train Epoch: 59 [12800/60000 (21%)]\tLoss: 19.433678\n",
            "Train Epoch: 59 [25600/60000 (43%)]\tLoss: 19.466564\n",
            "Train Epoch: 59 [38400/60000 (64%)]\tLoss: 19.334869\n",
            "Train Epoch: 59 [51200/60000 (85%)]\tLoss: 19.837811\n",
            "====> Epoch: 59 Average loss: 19.9930\n",
            "Train Epoch: 60 [0/60000 (0%)]\tLoss: 19.551086\n",
            "Train Epoch: 60 [12800/60000 (21%)]\tLoss: 19.766743\n",
            "Train Epoch: 60 [25600/60000 (43%)]\tLoss: 19.598585\n",
            "Train Epoch: 60 [38400/60000 (64%)]\tLoss: 20.279278\n",
            "Train Epoch: 60 [51200/60000 (85%)]\tLoss: 19.918665\n",
            "====> Epoch: 60 Average loss: 19.9688\n",
            "Train Epoch: 61 [0/60000 (0%)]\tLoss: 20.208832\n",
            "Train Epoch: 61 [12800/60000 (21%)]\tLoss: 20.652798\n",
            "Train Epoch: 61 [25600/60000 (43%)]\tLoss: 20.418936\n",
            "Train Epoch: 61 [38400/60000 (64%)]\tLoss: 20.546463\n",
            "Train Epoch: 61 [51200/60000 (85%)]\tLoss: 20.230373\n",
            "====> Epoch: 61 Average loss: 19.9809\n",
            "Train Epoch: 62 [0/60000 (0%)]\tLoss: 20.015524\n",
            "Train Epoch: 62 [12800/60000 (21%)]\tLoss: 19.805553\n",
            "Train Epoch: 62 [25600/60000 (43%)]\tLoss: 20.297035\n",
            "Train Epoch: 62 [38400/60000 (64%)]\tLoss: 19.643295\n",
            "Train Epoch: 62 [51200/60000 (85%)]\tLoss: 20.198145\n",
            "====> Epoch: 62 Average loss: 19.9854\n",
            "Train Epoch: 63 [0/60000 (0%)]\tLoss: 19.787220\n",
            "Train Epoch: 63 [12800/60000 (21%)]\tLoss: 21.218889\n",
            "Train Epoch: 63 [25600/60000 (43%)]\tLoss: 20.391674\n",
            "Train Epoch: 63 [38400/60000 (64%)]\tLoss: 20.161123\n",
            "Train Epoch: 63 [51200/60000 (85%)]\tLoss: 18.914305\n",
            "====> Epoch: 63 Average loss: 19.9523\n",
            "Train Epoch: 64 [0/60000 (0%)]\tLoss: 19.797693\n",
            "Train Epoch: 64 [12800/60000 (21%)]\tLoss: 20.239540\n",
            "Train Epoch: 64 [25600/60000 (43%)]\tLoss: 18.858208\n",
            "Train Epoch: 64 [38400/60000 (64%)]\tLoss: 18.825397\n",
            "Train Epoch: 64 [51200/60000 (85%)]\tLoss: 19.172796\n",
            "====> Epoch: 64 Average loss: 19.9900\n",
            "Train Epoch: 65 [0/60000 (0%)]\tLoss: 19.685177\n",
            "Train Epoch: 65 [12800/60000 (21%)]\tLoss: 19.182095\n",
            "Train Epoch: 65 [25600/60000 (43%)]\tLoss: 19.479059\n",
            "Train Epoch: 65 [38400/60000 (64%)]\tLoss: 19.389593\n",
            "Train Epoch: 65 [51200/60000 (85%)]\tLoss: 19.380960\n",
            "====> Epoch: 65 Average loss: 19.9869\n",
            "Train Epoch: 66 [0/60000 (0%)]\tLoss: 20.167095\n",
            "Train Epoch: 66 [12800/60000 (21%)]\tLoss: 20.252338\n",
            "Train Epoch: 66 [25600/60000 (43%)]\tLoss: 19.741390\n",
            "Train Epoch: 66 [38400/60000 (64%)]\tLoss: 20.630495\n",
            "Train Epoch: 66 [51200/60000 (85%)]\tLoss: 20.553547\n",
            "====> Epoch: 66 Average loss: 19.9792\n",
            "Train Epoch: 67 [0/60000 (0%)]\tLoss: 19.433235\n",
            "Train Epoch: 67 [12800/60000 (21%)]\tLoss: 20.450481\n",
            "Train Epoch: 67 [25600/60000 (43%)]\tLoss: 19.926147\n",
            "Train Epoch: 67 [38400/60000 (64%)]\tLoss: 19.639038\n",
            "Train Epoch: 67 [51200/60000 (85%)]\tLoss: 19.342503\n",
            "====> Epoch: 67 Average loss: 19.9212\n",
            "Train Epoch: 68 [0/60000 (0%)]\tLoss: 20.164402\n",
            "Train Epoch: 68 [12800/60000 (21%)]\tLoss: 20.763702\n",
            "Train Epoch: 68 [25600/60000 (43%)]\tLoss: 20.367674\n",
            "Train Epoch: 68 [38400/60000 (64%)]\tLoss: 20.136261\n",
            "Train Epoch: 68 [51200/60000 (85%)]\tLoss: 19.259853\n",
            "====> Epoch: 68 Average loss: 19.9728\n",
            "Train Epoch: 69 [0/60000 (0%)]\tLoss: 19.537922\n",
            "Train Epoch: 69 [12800/60000 (21%)]\tLoss: 19.463531\n",
            "Train Epoch: 69 [25600/60000 (43%)]\tLoss: 19.962637\n",
            "Train Epoch: 69 [38400/60000 (64%)]\tLoss: 19.154421\n",
            "Train Epoch: 69 [51200/60000 (85%)]\tLoss: 20.107792\n",
            "====> Epoch: 69 Average loss: 20.0060\n",
            "Train Epoch: 70 [0/60000 (0%)]\tLoss: 19.429169\n",
            "Train Epoch: 70 [12800/60000 (21%)]\tLoss: 19.656330\n",
            "Train Epoch: 70 [25600/60000 (43%)]\tLoss: 19.018200\n",
            "Train Epoch: 70 [38400/60000 (64%)]\tLoss: 20.829369\n",
            "Train Epoch: 70 [51200/60000 (85%)]\tLoss: 20.530434\n",
            "====> Epoch: 70 Average loss: 19.9711\n",
            "Train Epoch: 71 [0/60000 (0%)]\tLoss: 20.891111\n",
            "Train Epoch: 71 [12800/60000 (21%)]\tLoss: 20.874434\n",
            "Train Epoch: 71 [25600/60000 (43%)]\tLoss: 20.150364\n",
            "Train Epoch: 71 [38400/60000 (64%)]\tLoss: 19.340904\n",
            "Train Epoch: 71 [51200/60000 (85%)]\tLoss: 19.776705\n",
            "====> Epoch: 71 Average loss: 19.9495\n",
            "Train Epoch: 72 [0/60000 (0%)]\tLoss: 19.568319\n",
            "Train Epoch: 72 [12800/60000 (21%)]\tLoss: 20.498442\n",
            "Train Epoch: 72 [25600/60000 (43%)]\tLoss: 20.298260\n",
            "Train Epoch: 72 [38400/60000 (64%)]\tLoss: 20.582584\n",
            "Train Epoch: 72 [51200/60000 (85%)]\tLoss: 20.403816\n",
            "====> Epoch: 72 Average loss: 19.9683\n",
            "Train Epoch: 73 [0/60000 (0%)]\tLoss: 20.204195\n",
            "Train Epoch: 73 [12800/60000 (21%)]\tLoss: 19.504103\n",
            "Train Epoch: 73 [25600/60000 (43%)]\tLoss: 19.901312\n",
            "Train Epoch: 73 [38400/60000 (64%)]\tLoss: 19.625698\n",
            "Train Epoch: 73 [51200/60000 (85%)]\tLoss: 19.434811\n",
            "====> Epoch: 73 Average loss: 20.0770\n",
            "Train Epoch: 74 [0/60000 (0%)]\tLoss: 19.718067\n",
            "Train Epoch: 74 [12800/60000 (21%)]\tLoss: 20.045795\n",
            "Train Epoch: 74 [25600/60000 (43%)]\tLoss: 20.198214\n",
            "Train Epoch: 74 [38400/60000 (64%)]\tLoss: 20.791176\n",
            "Train Epoch: 74 [51200/60000 (85%)]\tLoss: 20.034580\n",
            "====> Epoch: 74 Average loss: 20.0382\n",
            "Train Epoch: 75 [0/60000 (0%)]\tLoss: 20.290472\n",
            "Train Epoch: 75 [12800/60000 (21%)]\tLoss: 20.127209\n",
            "Train Epoch: 75 [25600/60000 (43%)]\tLoss: 20.326889\n",
            "Train Epoch: 75 [38400/60000 (64%)]\tLoss: 19.833988\n",
            "Train Epoch: 75 [51200/60000 (85%)]\tLoss: 19.966194\n",
            "====> Epoch: 75 Average loss: 20.0209\n",
            "Train Epoch: 76 [0/60000 (0%)]\tLoss: 19.855915\n",
            "Train Epoch: 76 [12800/60000 (21%)]\tLoss: 20.895851\n",
            "Train Epoch: 76 [25600/60000 (43%)]\tLoss: 20.006308\n",
            "Train Epoch: 76 [38400/60000 (64%)]\tLoss: 20.698528\n",
            "Train Epoch: 76 [51200/60000 (85%)]\tLoss: 20.768475\n",
            "====> Epoch: 76 Average loss: 19.9936\n",
            "Train Epoch: 77 [0/60000 (0%)]\tLoss: 20.265030\n",
            "Train Epoch: 77 [12800/60000 (21%)]\tLoss: 19.788675\n",
            "Train Epoch: 77 [25600/60000 (43%)]\tLoss: 19.569397\n",
            "Train Epoch: 77 [38400/60000 (64%)]\tLoss: 18.895184\n",
            "Train Epoch: 77 [51200/60000 (85%)]\tLoss: 20.490814\n",
            "====> Epoch: 77 Average loss: 19.9518\n",
            "Train Epoch: 78 [0/60000 (0%)]\tLoss: 18.929314\n",
            "Train Epoch: 78 [12800/60000 (21%)]\tLoss: 19.905924\n",
            "Train Epoch: 78 [25600/60000 (43%)]\tLoss: 19.680864\n",
            "Train Epoch: 78 [38400/60000 (64%)]\tLoss: 19.425438\n",
            "Train Epoch: 78 [51200/60000 (85%)]\tLoss: 20.635155\n",
            "====> Epoch: 78 Average loss: 20.0116\n",
            "Train Epoch: 79 [0/60000 (0%)]\tLoss: 20.277582\n",
            "Train Epoch: 79 [12800/60000 (21%)]\tLoss: 19.815603\n",
            "Train Epoch: 79 [25600/60000 (43%)]\tLoss: 19.700512\n",
            "Train Epoch: 79 [38400/60000 (64%)]\tLoss: 20.674185\n",
            "Train Epoch: 79 [51200/60000 (85%)]\tLoss: 19.875868\n",
            "====> Epoch: 79 Average loss: 19.9980\n",
            "Train Epoch: 80 [0/60000 (0%)]\tLoss: 19.362125\n",
            "Train Epoch: 80 [12800/60000 (21%)]\tLoss: 20.819889\n",
            "Train Epoch: 80 [25600/60000 (43%)]\tLoss: 19.487560\n",
            "Train Epoch: 80 [38400/60000 (64%)]\tLoss: 21.043573\n",
            "Train Epoch: 80 [51200/60000 (85%)]\tLoss: 20.446434\n",
            "====> Epoch: 80 Average loss: 19.9827\n",
            "Train Epoch: 81 [0/60000 (0%)]\tLoss: 19.468512\n",
            "Train Epoch: 81 [12800/60000 (21%)]\tLoss: 19.273605\n",
            "Train Epoch: 81 [25600/60000 (43%)]\tLoss: 20.041609\n",
            "Train Epoch: 81 [38400/60000 (64%)]\tLoss: 19.951481\n",
            "Train Epoch: 81 [51200/60000 (85%)]\tLoss: 18.929602\n",
            "====> Epoch: 81 Average loss: 19.9741\n",
            "Train Epoch: 82 [0/60000 (0%)]\tLoss: 18.780941\n",
            "Train Epoch: 82 [12800/60000 (21%)]\tLoss: 20.124168\n",
            "Train Epoch: 82 [25600/60000 (43%)]\tLoss: 20.377705\n",
            "Train Epoch: 82 [38400/60000 (64%)]\tLoss: 20.129683\n",
            "Train Epoch: 82 [51200/60000 (85%)]\tLoss: 19.991135\n",
            "====> Epoch: 82 Average loss: 20.0037\n",
            "Train Epoch: 83 [0/60000 (0%)]\tLoss: 19.839615\n",
            "Train Epoch: 83 [12800/60000 (21%)]\tLoss: 20.728146\n",
            "Train Epoch: 83 [25600/60000 (43%)]\tLoss: 19.831543\n",
            "Train Epoch: 83 [38400/60000 (64%)]\tLoss: 20.829544\n",
            "Train Epoch: 83 [51200/60000 (85%)]\tLoss: 19.807051\n",
            "====> Epoch: 83 Average loss: 20.0196\n",
            "Train Epoch: 84 [0/60000 (0%)]\tLoss: 19.755901\n",
            "Train Epoch: 84 [12800/60000 (21%)]\tLoss: 19.442213\n",
            "Train Epoch: 84 [25600/60000 (43%)]\tLoss: 19.520329\n",
            "Train Epoch: 84 [38400/60000 (64%)]\tLoss: 19.618467\n",
            "Train Epoch: 84 [51200/60000 (85%)]\tLoss: 20.241470\n",
            "====> Epoch: 84 Average loss: 19.9815\n",
            "Train Epoch: 85 [0/60000 (0%)]\tLoss: 19.881094\n",
            "Train Epoch: 85 [12800/60000 (21%)]\tLoss: 20.257580\n",
            "Train Epoch: 85 [25600/60000 (43%)]\tLoss: 21.484465\n",
            "Train Epoch: 85 [38400/60000 (64%)]\tLoss: 20.048588\n",
            "Train Epoch: 85 [51200/60000 (85%)]\tLoss: 19.052692\n",
            "====> Epoch: 85 Average loss: 19.9676\n",
            "Train Epoch: 86 [0/60000 (0%)]\tLoss: 20.215981\n",
            "Train Epoch: 86 [12800/60000 (21%)]\tLoss: 18.986742\n",
            "Train Epoch: 86 [25600/60000 (43%)]\tLoss: 18.958574\n",
            "Train Epoch: 86 [38400/60000 (64%)]\tLoss: 20.513998\n",
            "Train Epoch: 86 [51200/60000 (85%)]\tLoss: 20.578459\n",
            "====> Epoch: 86 Average loss: 19.9838\n",
            "Train Epoch: 87 [0/60000 (0%)]\tLoss: 19.716812\n",
            "Train Epoch: 87 [12800/60000 (21%)]\tLoss: 19.868565\n",
            "Train Epoch: 87 [25600/60000 (43%)]\tLoss: 19.879950\n",
            "Train Epoch: 87 [38400/60000 (64%)]\tLoss: 20.061386\n",
            "Train Epoch: 87 [51200/60000 (85%)]\tLoss: 19.706427\n",
            "====> Epoch: 87 Average loss: 20.0559\n",
            "Train Epoch: 88 [0/60000 (0%)]\tLoss: 19.914566\n",
            "Train Epoch: 88 [12800/60000 (21%)]\tLoss: 18.996738\n",
            "Train Epoch: 88 [25600/60000 (43%)]\tLoss: 20.344408\n",
            "Train Epoch: 88 [38400/60000 (64%)]\tLoss: 20.187302\n",
            "Train Epoch: 88 [51200/60000 (85%)]\tLoss: 19.186714\n",
            "====> Epoch: 88 Average loss: 19.9628\n",
            "Train Epoch: 89 [0/60000 (0%)]\tLoss: 19.801460\n",
            "Train Epoch: 89 [12800/60000 (21%)]\tLoss: 19.017483\n",
            "Train Epoch: 89 [25600/60000 (43%)]\tLoss: 20.827053\n",
            "Train Epoch: 89 [38400/60000 (64%)]\tLoss: 19.816574\n",
            "Train Epoch: 89 [51200/60000 (85%)]\tLoss: 20.435274\n",
            "====> Epoch: 89 Average loss: 20.0036\n",
            "Train Epoch: 90 [0/60000 (0%)]\tLoss: 20.477852\n",
            "Train Epoch: 90 [12800/60000 (21%)]\tLoss: 20.003073\n",
            "Train Epoch: 90 [25600/60000 (43%)]\tLoss: 20.145725\n",
            "Train Epoch: 90 [38400/60000 (64%)]\tLoss: 18.925797\n",
            "Train Epoch: 90 [51200/60000 (85%)]\tLoss: 20.264698\n",
            "====> Epoch: 90 Average loss: 19.9716\n",
            "Train Epoch: 91 [0/60000 (0%)]\tLoss: 20.053185\n",
            "Train Epoch: 91 [12800/60000 (21%)]\tLoss: 19.602306\n",
            "Train Epoch: 91 [25600/60000 (43%)]\tLoss: 18.880344\n",
            "Train Epoch: 91 [38400/60000 (64%)]\tLoss: 19.625816\n",
            "Train Epoch: 91 [51200/60000 (85%)]\tLoss: 19.301960\n",
            "====> Epoch: 91 Average loss: 19.9868\n",
            "Train Epoch: 92 [0/60000 (0%)]\tLoss: 19.087227\n",
            "Train Epoch: 92 [12800/60000 (21%)]\tLoss: 19.725267\n",
            "Train Epoch: 92 [25600/60000 (43%)]\tLoss: 20.128942\n",
            "Train Epoch: 92 [38400/60000 (64%)]\tLoss: 20.544336\n",
            "Train Epoch: 92 [51200/60000 (85%)]\tLoss: 20.084749\n",
            "====> Epoch: 92 Average loss: 19.9785\n",
            "Train Epoch: 93 [0/60000 (0%)]\tLoss: 19.413857\n",
            "Train Epoch: 93 [12800/60000 (21%)]\tLoss: 19.567959\n",
            "Train Epoch: 93 [25600/60000 (43%)]\tLoss: 19.157410\n",
            "Train Epoch: 93 [38400/60000 (64%)]\tLoss: 19.510853\n",
            "Train Epoch: 93 [51200/60000 (85%)]\tLoss: 21.041794\n",
            "====> Epoch: 93 Average loss: 20.0073\n",
            "Train Epoch: 94 [0/60000 (0%)]\tLoss: 19.820127\n",
            "Train Epoch: 94 [12800/60000 (21%)]\tLoss: 19.994810\n",
            "Train Epoch: 94 [25600/60000 (43%)]\tLoss: 19.916447\n",
            "Train Epoch: 94 [38400/60000 (64%)]\tLoss: 19.613165\n",
            "Train Epoch: 94 [51200/60000 (85%)]\tLoss: 19.903763\n",
            "====> Epoch: 94 Average loss: 19.9261\n",
            "Train Epoch: 95 [0/60000 (0%)]\tLoss: 20.296707\n",
            "Train Epoch: 95 [12800/60000 (21%)]\tLoss: 20.020172\n",
            "Train Epoch: 95 [25600/60000 (43%)]\tLoss: 19.907627\n",
            "Train Epoch: 95 [38400/60000 (64%)]\tLoss: 20.480326\n",
            "Train Epoch: 95 [51200/60000 (85%)]\tLoss: 19.987366\n",
            "====> Epoch: 95 Average loss: 19.9673\n",
            "Train Epoch: 96 [0/60000 (0%)]\tLoss: 19.364233\n",
            "Train Epoch: 96 [12800/60000 (21%)]\tLoss: 19.281971\n",
            "Train Epoch: 96 [25600/60000 (43%)]\tLoss: 20.526403\n",
            "Train Epoch: 96 [38400/60000 (64%)]\tLoss: 20.352734\n",
            "Train Epoch: 96 [51200/60000 (85%)]\tLoss: 19.644115\n",
            "====> Epoch: 96 Average loss: 19.9941\n",
            "Train Epoch: 97 [0/60000 (0%)]\tLoss: 19.598963\n",
            "Train Epoch: 97 [12800/60000 (21%)]\tLoss: 20.328207\n",
            "Train Epoch: 97 [25600/60000 (43%)]\tLoss: 19.855190\n",
            "Train Epoch: 97 [38400/60000 (64%)]\tLoss: 20.523392\n",
            "Train Epoch: 97 [51200/60000 (85%)]\tLoss: 20.626560\n",
            "====> Epoch: 97 Average loss: 19.9997\n",
            "Train Epoch: 98 [0/60000 (0%)]\tLoss: 18.660061\n",
            "Train Epoch: 98 [12800/60000 (21%)]\tLoss: 20.143822\n",
            "Train Epoch: 98 [25600/60000 (43%)]\tLoss: 19.188547\n",
            "Train Epoch: 98 [38400/60000 (64%)]\tLoss: 19.798307\n",
            "Train Epoch: 98 [51200/60000 (85%)]\tLoss: 20.068108\n",
            "====> Epoch: 98 Average loss: 19.9700\n",
            "Train Epoch: 99 [0/60000 (0%)]\tLoss: 19.551344\n",
            "Train Epoch: 99 [12800/60000 (21%)]\tLoss: 19.678251\n",
            "Train Epoch: 99 [25600/60000 (43%)]\tLoss: 20.672653\n",
            "Train Epoch: 99 [38400/60000 (64%)]\tLoss: 19.570400\n",
            "Train Epoch: 99 [51200/60000 (85%)]\tLoss: 19.648155\n",
            "====> Epoch: 99 Average loss: 19.9695\n",
            "Train Epoch: 100 [0/60000 (0%)]\tLoss: 20.778875\n",
            "Train Epoch: 100 [12800/60000 (21%)]\tLoss: 19.638502\n",
            "Train Epoch: 100 [25600/60000 (43%)]\tLoss: 20.464951\n",
            "Train Epoch: 100 [38400/60000 (64%)]\tLoss: 20.087761\n",
            "Train Epoch: 100 [51200/60000 (85%)]\tLoss: 20.545635\n",
            "====> Epoch: 100 Average loss: 20.0218\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "H1oK2FA_LEip",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 405
        },
        "outputId": "fa99a482-9c15-4163-cae9-5b22698b6e6e"
      },
      "source": [
        "for batch_idx, data in enumerate(dataloader):\n",
        "    if batch_idx == 0:\n",
        "      img, _ = data\n",
        "      img = img.view(img.size(0), -1)\n",
        "      img = Variable(img)\n",
        "\n",
        "      mu, logvar = model.encode(img)\n",
        "      modelOutput = model.reparametrize(mu, logvar)\n",
        "      \n",
        "      predOutput = predModel(img)\n",
        "      print(torch.max(-1 * predOutput))"
      ],
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "tensor(3.8205, grad_fn=<MaxBackward1>)\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-10-869f07cb4ff9>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0;32mfor\u001b[0m \u001b[0mbatch_idx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdata\u001b[0m \u001b[0;32min\u001b[0m \u001b[0menumerate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdataloader\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mbatch_idx\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m       \u001b[0mimg\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m       \u001b[0mimg\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mimg\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mview\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimg\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m       \u001b[0mimg\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mVariable\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimg\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/torch/utils/data/dataloader.py\u001b[0m in \u001b[0;36m__next__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    343\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    344\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__next__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 345\u001b[0;31m         \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_next_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    346\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_num_yielded\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    347\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_dataset_kind\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0m_DatasetKind\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mIterable\u001b[0m \u001b[0;32mand\u001b[0m\u001b[0;31m \u001b[0m\u001b[0;31m\\\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/torch/utils/data/dataloader.py\u001b[0m in \u001b[0;36m_next_data\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    383\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_next_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    384\u001b[0m         \u001b[0mindex\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_next_index\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# may raise StopIteration\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 385\u001b[0;31m         \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_dataset_fetcher\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfetch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mindex\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# may raise StopIteration\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    386\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_pin_memory\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    387\u001b[0m             \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_utils\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpin_memory\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpin_memory\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/torch/utils/data/_utils/fetch.py\u001b[0m in \u001b[0;36mfetch\u001b[0;34m(self, possibly_batched_index)\u001b[0m\n\u001b[1;32m     42\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mfetch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpossibly_batched_index\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     43\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mauto_collation\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 44\u001b[0;31m             \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdataset\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0midx\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0midx\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mpossibly_batched_index\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     45\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     46\u001b[0m             \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdataset\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mpossibly_batched_index\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/torch/utils/data/_utils/fetch.py\u001b[0m in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m     42\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mfetch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpossibly_batched_index\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     43\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mauto_collation\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 44\u001b[0;31m             \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdataset\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0midx\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0midx\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mpossibly_batched_index\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     45\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     46\u001b[0m             \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdataset\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mpossibly_batched_index\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/torchvision/datasets/mnist.py\u001b[0m in \u001b[0;36m__getitem__\u001b[0;34m(self, index)\u001b[0m\n\u001b[1;32m     92\u001b[0m         \u001b[0;31m# doing this so that it is consistent with all other datasets\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     93\u001b[0m         \u001b[0;31m# to return a PIL Image\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 94\u001b[0;31m         \u001b[0mimg\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mImage\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfromarray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimg\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnumpy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmode\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'L'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     95\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     96\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtransform\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/PIL/Image.py\u001b[0m in \u001b[0;36mfromarray\u001b[0;34m(obj, mode)\u001b[0m\n\u001b[1;32m   2636\u001b[0m     \u001b[0;34m.\u001b[0m\u001b[0;34m.\u001b[0m \u001b[0mversionadded\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0;36m1.1\u001b[0m\u001b[0;36m.6\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2637\u001b[0m     \"\"\"\n\u001b[0;32m-> 2638\u001b[0;31m     \u001b[0marr\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mobj\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__array_interface__\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2639\u001b[0m     \u001b[0mshape\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0marr\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"shape\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2640\u001b[0m     \u001b[0mndim\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ]
    }
  ]
}