{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "MNISTtoy.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "Q_d-CIz_uoKk",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import torch\n",
        "import torchvision as tv\n",
        "import torchvision.transforms as transforms\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "from torch import optim\n",
        "from torch.autograd import Variable\n",
        "from torch.utils.data import DataLoader\n",
        "from torchvision.utils import save_image\n",
        "from torchvision.datasets import MNIST\n",
        "import os"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-ZmEczR4uzYl",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "if not os.path.exists('./vae_img'):\n",
        "    os.mkdir('./vae_img')\n",
        "\n",
        "if not os.path.exists('./vae_img_pred'):\n",
        "    os.mkdir('./vae_img_pred')\n",
        "\n",
        "\n",
        "def to_img(x):\n",
        "    x = x.clamp(0, 1)\n",
        "    x = x.view(x.size(0), 1, 28, 28)\n",
        "    return x\n",
        "\n",
        "\n",
        "num_epochs = 101\n",
        "batch_size = 128\n",
        "learning_rate = 1e-3\n",
        "\n",
        "img_transform = transforms.Compose([\n",
        "    transforms.ToTensor()\n",
        "    # transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5))\n",
        "])\n",
        "\n",
        "dataset = MNIST('./data', transform=img_transform, download=True)\n",
        "dataloader = DataLoader(dataset, batch_size=batch_size, shuffle=True)\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fNYWMIGMvkFb",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 52
        },
        "outputId": "fc545b82-344b-486e-da5b-3385e8afc35f"
      },
      "source": [
        "class VAE(nn.Module):\n",
        "    def __init__(self):\n",
        "        super(VAE, self).__init__()\n",
        "\n",
        "        self.fc1 = nn.Linear(784, 400)\n",
        "        self.fc21 = nn.Linear(400, 20)\n",
        "        self.fc22 = nn.Linear(400, 20)\n",
        "        self.fc3 = nn.Linear(20, 400)\n",
        "        self.fc4 = nn.Linear(400, 784)\n",
        "\n",
        "    def encode(self, x):\n",
        "        h1 = F.relu(self.fc1(x))\n",
        "        return self.fc21(h1), self.fc22(h1)\n",
        "\n",
        "    def reparametrize(self, mu, logvar):\n",
        "        std = logvar.mul(0.5).exp_()\n",
        "        if torch.cuda.is_available():\n",
        "            eps = torch.cuda.FloatTensor(std.size()).normal_()\n",
        "        else:\n",
        "            eps = torch.FloatTensor(std.size()).normal_()\n",
        "        eps = Variable(eps)\n",
        "        return eps.mul(std).add_(mu)\n",
        "\n",
        "    def decode(self, z):\n",
        "        h3 = F.relu(self.fc3(z))\n",
        "        return F.sigmoid(self.fc4(h3))\n",
        "\n",
        "    def forward(self, x):\n",
        "        mu, logvar = self.encode(x)\n",
        "        z = self.reparametrize(mu, logvar)\n",
        "        return self.decode(z), mu, logvar\n",
        "\n",
        "\n",
        "model = VAE()\n",
        "if torch.cuda.is_available():\n",
        "    model.cuda()\n",
        "\n",
        "reconstruction_function = nn.MSELoss(size_average=False)\n",
        "\n",
        "\n",
        "def loss_function(recon_x, x, mu, logvar):\n",
        "    \"\"\"\n",
        "    recon_x: generating images\n",
        "    x: origin images\n",
        "    mu: latent mean\n",
        "    logvar: latent log variance\n",
        "    \"\"\"\n",
        "    BCE = reconstruction_function(recon_x, x)  # mse loss\n",
        "    # loss = 0.5 * sum(1 + log(sigma^2) - mu^2 - sigma^2)\n",
        "    KLD_element = mu.pow(2).add_(logvar.exp()).mul_(-1).add_(1).add_(logvar)\n",
        "    KLD = torch.sum(KLD_element).mul_(-0.5)\n",
        "    # KL divergence\n",
        "    return BCE + KLD\n",
        "\n",
        "\n",
        "optimizer = optim.Adam(model.parameters(), lr=1e-3)"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/torch/nn/_reduction.py:43: UserWarning: size_average and reduce args will be deprecated, please use reduction='sum' instead.\n",
            "  warnings.warn(warning.format(ret))\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "iK0vjXBwLGxE",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 52
        },
        "outputId": "9c9cb576-1936-4046-a19f-31ee23903047"
      },
      "source": [
        "class VAEPredicter(nn.Module):\n",
        "    def __init__(self):\n",
        "        super(VAEPredicter, self).__init__()\n",
        "\n",
        "        self.fc1 = nn.Linear(784, 400)\n",
        "        self.fc11 = nn.Linear(400, 400)\n",
        "        self.fc21 = nn.Linear(400, 20)\n",
        "        self.fc22 = nn.Linear(400, 20)\n",
        "        self.fc3 = nn.Linear(20, 400)\n",
        "        self.fc4 = nn.Linear(400, 784)\n",
        "\n",
        "    def encode(self, x):\n",
        "        h1 = F.relu(self.fc1(x))\n",
        "        h2 = F.relu(self.fc11(h1))\n",
        "        return self.fc21(h2), self.fc22(h2)\n",
        "\n",
        "    def reparametrize(self, mu, logvar):\n",
        "        std = logvar.mul(0.5).exp_()\n",
        "        if torch.cuda.is_available():\n",
        "            eps = torch.cuda.FloatTensor(std.size()).normal_()\n",
        "        else:\n",
        "            eps = torch.FloatTensor(std.size()).normal_()\n",
        "        eps = Variable(eps)\n",
        "        return eps.mul(std).add_(mu)\n",
        "\n",
        "\n",
        "    def forward(self, x):\n",
        "        mu, logvar = self.encode(x)\n",
        "        z = self.reparametrize(mu, logvar)\n",
        "        return z\n",
        "\n",
        "\n",
        "predModel = VAEPredicter()\n",
        "if torch.cuda.is_available():\n",
        "    model.cuda()\n",
        "\n",
        "predict_function = nn.MSELoss(size_average=False)\n",
        "\n",
        "\n",
        "def pred_loss_function(pred_z, target_z):#, mu, logvar):\n",
        "    \"\"\"\n",
        "    recon_x: generating images\n",
        "    x: origin images\n",
        "    mu: latent mean\n",
        "    logvar: latent log variance\n",
        "    \"\"\"\n",
        "    BCE = predict_function(pred_z, target_z)  # mse loss\n",
        "    # loss = 0.5 * sum(1 + log(sigma^2) - mu^2 - sigma^2)\n",
        "    #KLD_element = mu.pow(2).add_(logvar.exp()).mul_(-1).add_(1).add_(logvar)\n",
        "    #KLD = torch.sum(KLD_element).mul_(-0.5)\n",
        "    # KL divergence\n",
        "    return BCE\n",
        "\n",
        "\n",
        "optimizer = optim.Adam(model.parameters(), lr=1e-3)"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/torch/nn/_reduction.py:43: UserWarning: size_average and reduce args will be deprecated, please use reduction='sum' instead.\n",
            "  warnings.warn(warning.format(ret))\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3BlVeCd-1dbm",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 319
        },
        "outputId": "e91333e9-a3fa-4a0e-b108-5241ec2d5457"
      },
      "source": [
        "for epoch in range(num_epochs):\n",
        "    model.train()\n",
        "    train_loss = 0\n",
        "    for batch_idx, data in enumerate(dataloader):\n",
        "        img, _ = data\n",
        "        img = img.view(img.size(0), -1)\n",
        "        img = Variable(img)\n",
        "        if torch.cuda.is_available():\n",
        "            img = img.cuda()\n",
        "        optimizer.zero_grad()\n",
        "        recon_batch, mu, logvar = model(img)\n",
        "        loss = loss_function(recon_batch, img, mu, logvar)\n",
        "        loss.backward()\n",
        "        train_loss += loss.item()\n",
        "        optimizer.step()\n",
        "        if batch_idx % 100 == 0:\n",
        "            print('Train Epoch: {} [{}/{} ({:.0f}%)]\\tLoss: {:.6f}'.format(\n",
        "                epoch,\n",
        "                batch_idx * len(img),\n",
        "                len(dataloader.dataset), 100. * batch_idx / len(dataloader),\n",
        "                loss.item() / len(img)))\n",
        "\n",
        "    print('====> Epoch: {} Average loss: {:.4f}'.format(\n",
        "        epoch, train_loss / len(dataloader.dataset)))\n",
        "    if epoch % 10 == 0:\n",
        "        save = to_img(recon_batch.cpu().data)\n",
        "        save_image(save, './vae_img/image_{}.png'.format(epoch))\n",
        "model.train(mode=False)\n",
        "torch.save(model.state_dict(), './vae.pth')"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/torch/nn/functional.py:1351: UserWarning: nn.functional.sigmoid is deprecated. Use torch.sigmoid instead.\n",
            "  warnings.warn(\"nn.functional.sigmoid is deprecated. Use torch.sigmoid instead.\")\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Train Epoch: 0 [0/60000 (0%)]\tLoss: 185.769028\n",
            "Train Epoch: 0 [12800/60000 (21%)]\tLoss: 51.356354\n",
            "Train Epoch: 0 [25600/60000 (43%)]\tLoss: 42.840378\n",
            "Train Epoch: 0 [38400/60000 (64%)]\tLoss: 42.023727\n",
            "Train Epoch: 0 [51200/60000 (85%)]\tLoss: 38.964962\n",
            "====> Epoch: 0 Average loss: 45.6278\n",
            "Train Epoch: 1 [0/60000 (0%)]\tLoss: 36.925941\n",
            "Train Epoch: 1 [12800/60000 (21%)]\tLoss: 37.306335\n",
            "Train Epoch: 1 [25600/60000 (43%)]\tLoss: 34.015518\n",
            "Train Epoch: 1 [38400/60000 (64%)]\tLoss: 33.826256\n",
            "Train Epoch: 1 [51200/60000 (85%)]\tLoss: 33.360420\n",
            "====> Epoch: 1 Average loss: 35.0348\n",
            "Train Epoch: 2 [0/60000 (0%)]\tLoss: 35.772167\n",
            "Train Epoch: 2 [12800/60000 (21%)]\tLoss: 33.084648\n",
            "Train Epoch: 2 [25600/60000 (43%)]\tLoss: 33.256634\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "T0At9m43U1pj",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "for epoch in range(num_epochs):\n",
        "    predModel.train()\n",
        "    train_loss = 0\n",
        "    for batch_idx, data in enumerate(dataloader):\n",
        "        img, _ = data\n",
        "        img = img.view(img.size(0), -1)\n",
        "        img = Variable(img)\n",
        "        if torch.cuda.is_available():\n",
        "            img = img.cuda()\n",
        "        optimizer.zero_grad()\n",
        "        mu, logvar = model.encode(img)\n",
        "        modelOutput = model.reparametrize(mu, logvar)\n",
        "        \n",
        "        predOutput = predModel(img)\n",
        "        recon_batch = model.decode(predOutput)\n",
        "        predLoss = pred_loss_function(predOutput, modelOutput)\n",
        "        predLoss.backward()\n",
        "        train_loss += predLoss.item()\n",
        "        optimizer.step()\n",
        "        if batch_idx % 100 == 0:\n",
        "            print('Train Epoch: {} [{}/{} ({:.0f}%)]\\tLoss: {:.6f}'.format(\n",
        "                epoch,\n",
        "                batch_idx * len(img),\n",
        "                len(dataloader.dataset), 100. * batch_idx / len(dataloader),\n",
        "                predLoss.item() / len(img)))\n",
        "\n",
        "    print('====> Epoch: {} Average loss: {:.4f}'.format(\n",
        "        epoch, train_loss / len(dataloader.dataset)))\n",
        "    if epoch % 10 == 0:\n",
        "        save = to_img(recon_batch.cpu().data)\n",
        "        save_image(save, './vae_img_pred/image_{}.png'.format(epoch))\n",
        "\n",
        "torch.save(predModel.state_dict(), './vaePred.pth')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "H1oK2FA_LEip",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}